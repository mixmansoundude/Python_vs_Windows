# yamllint disable rule:line-length rule:truthy rule:colons rule:document-start
name: Codex - Auto Iterate on CI Failure

on:
  push:
    branches: ['**']
  workflow_dispatch: {}

permissions:
  actions: write
  contents: write
  pull-requests: write

defaults:
  run:
    shell: bash

concurrency:
  group: codex-iterate-${{ github.sha }}
  cancel-in-progress: true

jobs:
  iterate:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MAX_ATTEMPTS: '4'
      OPENAI_MODEL: gpt-4o-mini
      POLL_TIMEOUT_SECONDS: '1200'
      POLL_INTERVAL_SECONDS: '10'
    steps:
      - name: Debug event
        run: |
          echo "event=${{ github.event_name }}"
          echo "ref_name=${{ github.ref_name }}"
          echo "sha=${{ github.sha }}"
          echo "actor=${{ github.actor }}"
          echo "workflow=${{ github.workflow }}"
          echo "run_id=${{ github.run_id }}"

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Configure git
        run: |
          git config user.name "github-actions"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Gather context
        id: ctx
        run: |
          set -euo pipefail
          branch="${{ github.ref_name }}"
          sha="${{ github.sha }}"
          run_id="${{ github.run_id }}"
          run_url="https://github.com/${{ github.repository }}/actions/runs/${run_id}"
          branch_slug=$(printf '%s' "$branch" | tr ':/ ' '---')
          {
            echo "branch=$branch"
            echo "branch_slug=$branch_slug"
            echo "head_sha=$sha"
            echo "run_id=$run_id"
            echo "run_url=$run_url"
          } >> "$GITHUB_OUTPUT"

      - name: Poll workflow runs for this commit
        id: poll
        uses: actions/github-script@v7
        env:
          POLL_TIMEOUT_SECONDS: ${{ env.POLL_TIMEOUT_SECONDS }}
          POLL_INTERVAL_SECONDS: ${{ env.POLL_INTERVAL_SECONDS }}
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const sha = context.sha;
            const selfRunId = String(context.runId || "");
            const selfName = (context.workflow || "").toLowerCase();
            const timeoutMs = parseInt(process.env.POLL_TIMEOUT_SECONDS || "900") * 1000;
            const intervalMs = parseInt(process.env.POLL_INTERVAL_SECONDS || "10") * 1000;
            const deadline = Date.now() + timeoutMs;

            async function listRuns() {
              const { data } = await github.rest.actions.listWorkflowRunsForRepo({
                owner,
                repo,
                head_sha: sha,
                per_page: 100,
              });
              return (data.workflow_runs || []).filter(run => {
                if (!run) return false;
                const id = String(run.id);
                const name = (run.name || "").toLowerCase();
                return id !== selfRunId && name !== selfName;
              });
            }

            let lastSnapshot = [];
            let chosen = null;
            while (Date.now() < deadline) {
              const runs = await listRuns();
              lastSnapshot = runs.map(r => ({ id: r.id, name: r.name, status: r.status, conclusion: r.conclusion }));
              if (!runs.length) {
                await new Promise(r => setTimeout(r, intervalMs));
                continue;
              }

              const completed = runs.filter(r => r.status === "completed");
              if (!completed.length) {
                await new Promise(r => setTimeout(r, intervalMs));
                continue;
              }

              chosen = completed.sort((a, b) => new Date(b.updated_at || 0) - new Date(a.updated_at || 0))[0];
              break;
            }

            core.setOutput("snapshot", JSON.stringify(lastSnapshot));
            if (!chosen) {
              core.setOutput("picked_id", "");
              core.setOutput("picked_conclusion", "");
              core.setOutput("picked_name", "");
              return;
            }

            core.setOutput("picked_id", String(chosen.id));
            core.setOutput("picked_conclusion", chosen.conclusion || "");
            core.setOutput("picked_name", chosen.name || "");

      - name: Fetch upstream run metadata
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: upstream
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          run_id="${RUN_ID}"
          repo="${{ github.repository }}"
          meta_dir="$RUNNER_TEMP/upstream"
          mkdir -p "$meta_dir"

          run_json="$meta_dir/run.json"
          gh api repos/${repo}/actions/runs/${run_id} > "$run_json" || true
          conclusion=$(jq -r '.conclusion // ""' "$run_json" 2>/dev/null || true)
          echo "conclusion=$conclusion" >> "$GITHUB_OUTPUT"

          summary_file="$meta_dir/summary.md"
          if gh run view "$run_id" --json summary --jq '.summary' > "$summary_file" 2>/dev/null; then
            if [ ! -s "$summary_file" ]; then
              rm -f "$summary_file"
            fi
          else
            rm -f "$summary_file"
          fi
          if [ -f "$summary_file" ]; then
            echo "summary_path=$summary_file" >> "$GITHUB_OUTPUT"
          else
            echo "summary_path=" >> "$GITHUB_OUTPUT"
          fi

          artifacts_json="$meta_dir/artifacts.json"
          gh api repos/${repo}/actions/runs/${run_id}/artifacts?per_page=100 > "$artifacts_json" || true
          ndjson_path=""
          ndjson_name=""
          if [ -s "$artifacts_json" ]; then
            jq -r '.artifacts[] | select((.expired // false) | not) | [.id,.name] | @tsv' "$artifacts_json" | while IFS=$'\t' read -r art_id art_name; do
              if [ -z "$art_id" ] || [ -z "$art_name" ]; then
                continue
              fi
              if ! printf '%s\n' "$art_name" | grep -qiE 'ndjson|test-results'; then
                continue
              fi
              zipfile="$meta_dir/$art_id.zip"
              gh api repos/${repo}/actions/artifacts/${art_id}/zip > "$zipfile" || continue
              dest="$meta_dir/artifact_$art_id"
              mkdir -p "$dest"
              unzip -q "$zipfile" -d "$dest" || continue
              candidate=$(find "$dest" -type f -name 'tests~test-results.ndjson' -o -name '*test-results.ndjson' | head -n 1 || true)
              if [ -n "$candidate" ]; then
                ndjson_path="$meta_dir/upstream_test-results.ndjson"
                ndjson_name="$art_name"
                cp "$candidate" "$ndjson_path"
                break
              fi
            done
          fi
          if [ -n "$ndjson_path" ] && [ -s "$ndjson_path" ]; then
            echo "ndjson_path=$ndjson_path" >> "$GITHUB_OUTPUT"
            echo "ndjson_source=$ndjson_name" >> "$GITHUB_OUTPUT"
          else
            echo "ndjson_path=" >> "$GITHUB_OUTPUT"
            echo "ndjson_source=" >> "$GITHUB_OUTPUT"
          fi

      - name: Fetch upstream logs (tail)
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: logtail
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          zipfile="$RUNNER_TEMP/upstream_logs.zip"
          gh api repos/${{ github.repository }}/actions/runs/${RUN_ID}/logs > "$zipfile" || true
          extract_dir="$RUNNER_TEMP/upstream_logs"
          mkdir -p "$extract_dir"
          unzip -q "$zipfile" -d "$extract_dir" || true
          tail_file="$RUNNER_TEMP/upstream_log_tail.txt"
          : > "$tail_file"
          if [ -d "$extract_dir" ]; then
            find "$extract_dir" -type f -name '*.txt' -printf '%s %p\n' | sort -nr | head -n 1 | awk '{print $2}' | while read -r largest; do
              [ -f "$largest" ] && tail -n 200 "$largest" > "$tail_file"
            done
          fi
          if [ -s "$tail_file" ]; then
            echo "path=$tail_file" >> "$GITHUB_OUTPUT"
          else
            echo "path=" >> "$GITHUB_OUTPUT"
          fi
          echo "extract_dir=$extract_dir" >> "$GITHUB_OUTPUT"

      - name: Fetch failing job metadata
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: jobmeta
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          jobs_json="$RUNNER_TEMP/upstream_jobs.json"
          gh api repos/${{ github.repository }}/actions/runs/${RUN_ID}/jobs?per_page=100 > "$jobs_json" || true
          failed_id=$(jq -r '.jobs[] | select(.conclusion=="failure") | .id' "$jobs_json" 2>/dev/null | head -n 1)
          failed_name=$(jq -r '.jobs[] | select(.conclusion=="failure") | .name' "$jobs_json" 2>/dev/null | head -n 1)
          if [ "$failed_id" = "null" ]; then failed_id=""; fi
          if [ "$failed_name" = "null" ]; then failed_name=""; fi
          echo "failed_id=$failed_id" >> "$GITHUB_OUTPUT"
          echo "failed_name=$failed_name" >> "$GITHUB_OUTPUT"
          echo "jobs_path=$jobs_json" >> "$GITHUB_OUTPUT"

      - name: Focus failing job logs
        if: ${{ steps.logtail.outputs.extract_dir != '' && (steps.jobmeta.outputs.failed_id != '' || steps.jobmeta.outputs.failed_name != '') }}
        id: logfocus
        env:
          EXTRACT_DIR: ${{ steps.logtail.outputs.extract_dir }}
          JOB_ID: ${{ steps.jobmeta.outputs.failed_id }}
          JOB_NAME: ${{ steps.jobmeta.outputs.failed_name }}
        run: |
          set -euo pipefail
          focus_path="$RUNNER_TEMP/failing_job_focus.txt"
          : > "$focus_path"
            if [ -f tools/focus_logs.py ]; then
              python tools/focus_logs.py "$EXTRACT_DIR" "$focus_path" "$JOB_ID" "$JOB_NAME" || true
            else
              EXTRACT_DIR="$EXTRACT_DIR" FOCUS_OUTPUT="$focus_path" python tools/focus_logs_fallback.py || true
            fi
          if [ -s "$focus_path" ]; then
            echo "path=$focus_path" >> "$GITHUB_OUTPUT"
          else
            echo "path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Evaluate iterate gate
        id: gate
        env:
          RUN_CONCLUSION: ${{ steps.upstream.outputs.conclusion }}
          NDJSON_PATH: ${{ steps.upstream.outputs.ndjson_path }}
          SUMMARY_PATH: ${{ steps.upstream.outputs.summary_path }}
          SNAPSHOT: ${{ steps.poll.outputs.snapshot }}
        run: |
          set -euo pipefail
          summary_path="${SUMMARY_PATH:-}"
          ndjson_path="${NDJSON_PATH:-}"
          run_conclusion="${RUN_CONCLUSION:-}"
          reason=""
          should_iterate="false"

          if [ -z "$run_conclusion" ] || [ "$run_conclusion" != "success" ]; then
            should_iterate="true"
            reason="workflow_conclusion_${run_conclusion:-unknown}"
          fi

          ndjson_reason=""
          if [ -z "$ndjson_path" ] || [ ! -f "$ndjson_path" ]; then
            should_iterate="true"
            ndjson_reason="ndjson_missing"
          else
            if [ ! -s "$ndjson_path" ]; then
              should_iterate="true"
              ndjson_reason="ndjson_empty"
            elif grep -q '"pass"[[:space:]]*:[[:space:]]*false' "$ndjson_path"; then
              should_iterate="true"
              ndjson_reason="ndjson_has_failures"
            fi
          fi

          summary_reason=""
          if [ -n "$summary_path" ] && [ -f "$summary_path" ]; then
            if grep -qi 'First failure' "$summary_path"; then
              should_iterate="true"
              summary_reason="summary_first_failure"
            fi
            # GitHub does not expose workflow_run outputs across workflows, so we scan the
            # rendered summary for the gate verdict string written by batch-check.
            if grep -qi 'verdict[[:space:]]*[:=][[:space:]]*fail' "$summary_path"; then
              should_iterate="true"
              if [ -n "$summary_reason" ]; then
                summary_reason="$summary_reason,summary_gate_verdict_fail"
              else
                summary_reason="summary_gate_verdict_fail"
              fi
            fi
          fi

          reasons=()
          if [ -n "$reason" ]; then reasons+=("$reason"); fi
          if [ -n "$ndjson_reason" ]; then reasons+=("$ndjson_reason"); fi
          if [ -n "$summary_reason" ]; then reasons+=("$summary_reason"); fi
          if [ "${#reasons[@]}" -gt 0 ]; then
            gate_reason=$(IFS=','; echo "${reasons[*]}")
          else
            gate_reason="all_checks_green"
          fi

          echo "should_iterate=$should_iterate" >> "$GITHUB_OUTPUT"
          echo "reason=$gate_reason" >> "$GITHUB_OUTPUT"

          {
            echo "### Poll summary"
            echo '```json'
            printf '%s\n' "${SNAPSHOT:-[]}" | jq '.' || printf '%s\n' "${SNAPSHOT:-[]}" || true
            echo '```'
            if [ "$should_iterate" != "true" ]; then
              echo
              echo "gate: skipped ($gate_reason)"
            else
              echo
              echo "gate: proceed ($gate_reason)"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Stop after gate skip
        if: ${{ steps.gate.outputs.should_iterate != 'true' }}
        run: |
          echo "No iteration required." >> "$GITHUB_STEP_SUMMARY"

      - name: Prepare iterate workspace
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: prepare
        env:
          NDJSON_PATH: ${{ steps.upstream.outputs.ndjson_path }}
          SUMMARY_PATH: ${{ steps.upstream.outputs.summary_path }}
        run: |
          set -euo pipefail
          status="$RUNNER_TEMP/iterate_status.txt"
          : > "$status"
          echo "status_path=$status" >> "$GITHUB_OUTPUT"
          if [ -n "$NDJSON_PATH" ] && [ -f "$NDJSON_PATH" ]; then
            echo "ndjson_path=$NDJSON_PATH" >> "$GITHUB_OUTPUT"
          else
            echo "ndjson_path=" >> "$GITHUB_OUTPUT"
          fi
          if [ -n "$SUMMARY_PATH" ] && [ -f "$SUMMARY_PATH" ]; then
            echo "summary_path=$SUMMARY_PATH" >> "$GITHUB_OUTPUT"
          else
            echo "summary_path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Collect iterate inputs
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: inputs
        env:
          STATUS_PATH: ${{ steps.prepare.outputs.status_path }}
          SUMMARY_PATH: ${{ steps.prepare.outputs.summary_path }}
          NDJSON_PATH: ${{ steps.prepare.outputs.ndjson_path }}
        run: |
          set -euo pipefail
          inputs_dir="$RUNNER_TEMP/iterate_inputs"
          mkdir -p "$inputs_dir"

          copy_or_placeholder() {
            local src="$1"
            local dest="$2"
            if [ -f "$src" ]; then
              cp "$src" "$inputs_dir/$dest"
            else
              printf 'missing: %s\n' "$src" > "$inputs_dir/$dest.missing.txt"
            fi
          }

          copy_or_placeholder "tests/~test-results.ndjson" "test-results.ndjson"
          copy_or_placeholder "tests/~test-summary.txt" "test-summary.txt"
          copy_or_placeholder "dynamic_tests.log" "dynamic_tests.log"
          copy_or_placeholder "tests/~dynamic-run.log" "dynamic-run.log"

          find tests -maxdepth 2 -type f -name '*.log' -path 'tests/~selftest_*/*' -print0 | while IFS= read -r -d '' log; do
            rel=${log#tests/}
            cp "$log" "$inputs_dir/${rel//\//_}" 2>/dev/null || true
          done

          if [ -n "$SUMMARY_PATH" ] && [ -f "$SUMMARY_PATH" ]; then
            cp "$SUMMARY_PATH" "$inputs_dir/upstream_summary.md"
          else
            echo 'missing upstream summary' > "$inputs_dir/upstream_summary.md"
          fi

          if [ -n "$NDJSON_PATH" ] && [ -f "$NDJSON_PATH" ]; then
            cp "$NDJSON_PATH" "$inputs_dir/upstream_test-results.ndjson"
          else
            echo 'missing upstream ndjson' > "$inputs_dir/upstream_test-results.ndjson.txt"
          fi

          copy_or_placeholder "${STATUS_PATH:-$RUNNER_TEMP/iterate_status.txt}" "iterate_status_snapshot.txt"

          if [ ! -f "$inputs_dir/placeholder.txt" ]; then
            echo 'iterate inputs collected' > "$inputs_dir/placeholder.txt"
          fi

          echo "inputs_dir=$inputs_dir" >> "$GITHUB_OUTPUT"

      - name: Upload iterate inputs
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-inputs-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ steps.inputs.outputs.inputs_dir }}
          if-no-files-found: ignore
          retention-days: 14

      - name: Build base prompt
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: prompt
        env:
          NDJSON_PATH: ${{ steps.prepare.outputs.ndjson_path }}
          SUMMARY_PATH: ${{ steps.prepare.outputs.summary_path }}
          STRUCT_PATH: ${{ steps.upstream.outputs.ndjson_path }}
          LOG_PATH: ${{ steps.logtail.outputs.path }}
          FOCUS_PATH: ${{ steps.logfocus.outputs.path }}
          BRANCH: ${{ steps.ctx.outputs.branch }}
          SHA: ${{ steps.ctx.outputs.head_sha }}
          REPO: ${{ github.repository }}
        run: |
          set -euo pipefail
          base="$RUNNER_TEMP/base_prompt.txt"
          {
            echo "You are Codex. You have a working copy of the repository checked out."
            echo "Focus on repairing the CI failure described below."
            echo
            echo "Repo: ${REPO}"
            echo "Branch: ${BRANCH}"
            echo "Commit: ${SHA}"
            echo
            echo "Instructions: Fix only what failed. Make minimal, targeted changes."
            echo "Return a single unified diff enclosed in one \`\`\`diff code fence."
            echo
            if [ -n "$SUMMARY_PATH" ] && [ -f "$SUMMARY_PATH" ]; then
              echo "----- Upstream job summary (truncated) -----"
              head -n 120 "$SUMMARY_PATH"
              echo
            fi
            if [ -n "$NDJSON_PATH" ] && [ -f "$NDJSON_PATH" ]; then
              echo "----- tests/~test-results.ndjson (first 40 lines) -----"
              head -n 40 "$NDJSON_PATH"
              echo
            fi
            if [ -n "$FOCUS_PATH" ] && [ -f "$FOCUS_PATH" ]; then
              echo "----- Focused failing job log (tail) -----"
              sed -e 's/[^[:print:]\t]/?/g' "$FOCUS_PATH" | tail -n 200
              echo
            elif [ -n "$LOG_PATH" ] && [ -f "$LOG_PATH" ]; then
              echo "----- Failing job log tail -----"
              sed -e 's/[^[:print:]\t]/?/g' "$LOG_PATH"
              echo
            fi
          } > "$base"
          echo "base_prompt=$base" >> "$GITHUB_OUTPUT"

      - name: Preflight auth mini chat
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: preflight
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MODEL: ${{ env.OPENAI_MODEL }}
          STATUS_PATH: ${{ steps.prepare.outputs.status_path }}
        run: |
          set -euo pipefail
          status_file="${STATUS_PATH:-$RUNNER_TEMP/iterate_status.txt}"
          req="$RUNNER_TEMP/preflight_llm_req.json"
          res="$RUNNER_TEMP/preflight_llm_res.json"
          content="$RUNNER_TEMP/preflight_llm_content.txt"
          : > "$req"
          : > "$res"
          : > "$content"
          ok="false"
          http_code="000"
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "No API key present" >> "$status_file"
            echo "ok=false" >> "$GITHUB_OUTPUT"
            echo "http=000" >> "$GITHUB_OUTPUT"
            exit 0
          fi

            jq -n \
              --arg model "$MODEL" \
              '{
                model: $model,
                input: [
                  {role: "user", content: [{type: "input_text", text: "ping"}]}
                ],
                max_output_tokens: 16,
                temperature: 0.0
              }' > "$req"
          http_code=$(curl -sS -o "$res" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$req" || true)
          if [ "$http_code" = "200" ]; then
            ok="true"
          else
            body="$RUNNER_TEMP/auth_body.json"
            cp "$res" "$body"
            echo "Saved failure body to $body" >> "$status_file"
          fi
          jq -r '(
            .output_text //
            (.output[]? | .content[]? | select(.type=="output_text") | .text) //
            (.output[0]? | .content[0]? | .text // "")
          )' "$res" > "$content" 2>/dev/null || true
          echo "Preflight http: $http_code" >> "$status_file"
          echo "ok=$ok" >> "$GITHUB_OUTPUT"
          echo "http=$http_code" >> "$GITHUB_OUTPUT"

      - name: Iterate attempts
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.preflight.outputs.ok == 'true' }}
        id: attempts
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MODEL: ${{ env.OPENAI_MODEL }}
          MAX_ATTEMPTS: ${{ env.MAX_ATTEMPTS }}
          STATUS_PATH: ${{ steps.prepare.outputs.status_path }}
          BASE_PROMPT: ${{ steps.prompt.outputs.base_prompt }}
          BRANCH: ${{ steps.ctx.outputs.branch }}
        run: |
          set -euo pipefail
          status_file="${STATUS_PATH:-$RUNNER_TEMP/iterate_status.txt}"
          preflight_req="$RUNNER_TEMP/preflight_llm_req.json"
          preflight_res="$RUNNER_TEMP/preflight_llm_res.json"
          preflight_content="$RUNNER_TEMP/preflight_llm_content.txt"
          auth_body="$RUNNER_TEMP/auth_body.json"
          max=${MAX_ATTEMPTS:-4}
          branch="${BRANCH:-${GITHUB_REF_NAME}}"
          attempt=1
          committed="false"
          while [ "$attempt" -le "$max" ]; do
            echo "attempt $attempt/$max" | tee -a "$status_file"
            attempt_dir="$RUNNER_TEMP/iterate_attempt_$attempt"
            mkdir -p "$attempt_dir"
            prompt_file="$attempt_dir/prompt.txt"
            if [ -n "${BASE_PROMPT:-}" ] && [ -f "$BASE_PROMPT" ]; then
              cat "$BASE_PROMPT" > "$prompt_file"
            fi
            {
              echo
              echo "Attempt $attempt of $max. Fix only what failed and keep changes minimal."
            } >> "$prompt_file"

            jq -Rs '.' < "$prompt_file" > "$attempt_dir/prompt.json"
            req="$attempt_dir/llm_req.json"
            res="$attempt_dir/llm_res.json"
            out="$attempt_dir/llm_content.txt"
              prompt_json=$(cat "$attempt_dir/prompt.json")
              jq -n \
                --arg model "$MODEL" \
                --argjson prompt "$prompt_json" \
                '{
                  model: $model,
                  input: [
                    {role: "system", content: [{type: "input_text", text: "You return only one unified diff."}]},
                    {role: "user", content: [{type: "input_text", text: $prompt}]}
                  ],
                  max_output_tokens: 2000,
                  temperature: 0.15
                }' > "$req"
            : > "$attempt_dir/codex_exec.log"
            http_code=$(curl -sS -o "$res" -w "%{http_code}" \
              https://api.openai.com/v1/responses \
              -H "authorization: Bearer $OPENAI_API_KEY" \
              -H "content-type: application/json" \
              -d @"$req" || true)
            echo "HTTP $http_code" >> "$attempt_dir/codex_exec.log"
            printf 'LLM HTTP %s\n' "$http_code" >> "$status_file"
            jq -r '(
              .output_text //
              (.output[]? | .content[]? | select(.type=="output_text") | .text) //
              (.output[0]? | .content[0]? | .text // "")
            )' "$res" > "$out" 2>/dev/null || true
            patch="$attempt_dir/patch.diff"
              if python tools/extract_diff_from_llm.py "$out" "$patch"
              then
                echo "Extracted diff" >> "$status_file"
              else
              echo "No diff block found" >> "$status_file"
            fi

            applied="false"
            if [ -s "$patch" ] && ! grep -qx '# no changes' "$patch"; then
              if git apply -p0 --index "$patch" >> "$attempt_dir/codex_exec.log" 2>&1; then
                applied="true"
              elif git apply -p1 --index "$patch" >> "$attempt_dir/codex_exec.log" 2>&1; then
                applied="true"
              else
                echo "git apply failed" >> "$status_file"
              fi
            else
              echo "Patch empty" >> "$status_file"
            fi

            if [ "$applied" = "true" ]; then
              staged=$(git diff --cached --name-only)
              if [ -n "$staged" ]; then
                git commit -m "codex: attempt $attempt/$max â€“ applied model patch"  >> "$attempt_dir/codex_exec.log" 2>&1
                git push origin HEAD:"$branch" >> "$attempt_dir/codex_exec.log" 2>&1
                committed="true"
                echo "commit_pushed=true" >> "$GITHUB_OUTPUT"
                echo "Commit pushed on attempt $attempt" >> "$status_file"
                cp "$status_file" "$attempt_dir/iterate_status.txt"
                for src in "$preflight_req" "$preflight_res" "$preflight_content" "$auth_body"; do
                  [ -f "$src" ] && cp "$src" "$attempt_dir/$(basename "$src")"
                done
                echo "attempt_${attempt}_dir=$attempt_dir" >> "$GITHUB_OUTPUT"
                break
              else
                echo "git diff empty after apply" >> "$status_file"
                git reset --hard HEAD
              fi
            fi

            cp "$status_file" "$attempt_dir/iterate_status.txt"
            for src in "$preflight_req" "$preflight_res" "$preflight_content" "$auth_body"; do
              [ -f "$src" ] && cp "$src" "$attempt_dir/$(basename "$src")"
            done
            echo "attempt_${attempt}_dir=$attempt_dir" >> "$GITHUB_OUTPUT"
            attempt=$((attempt+1))
          done
          if [ "$committed" != "true" ]; then
            echo "commit_pushed=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload diagnostics (attempt 1)
        if: ${{ steps.attempts.outputs.attempt_1_dir != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}-1
          path: ${{ steps.attempts.outputs.attempt_1_dir }}
          if-no-files-found: warn
          retention-days: 14

      - name: Upload diagnostics (attempt 2)
        if: ${{ steps.attempts.outputs.attempt_2_dir != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}-2
          path: ${{ steps.attempts.outputs.attempt_2_dir }}
          if-no-files-found: warn
          retention-days: 14

      - name: Upload diagnostics (attempt 3)
        if: ${{ steps.attempts.outputs.attempt_3_dir != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}-3
          path: ${{ steps.attempts.outputs.attempt_3_dir }}
          if-no-files-found: warn
          retention-days: 14

      - name: Upload diagnostics (attempt 4)
        if: ${{ steps.attempts.outputs.attempt_4_dir != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}-4
          path: ${{ steps.attempts.outputs.attempt_4_dir }}
          if-no-files-found: warn
          retention-days: 14

      - name: Upload diagnostics when preflight failed
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.preflight.outputs.ok != 'true' }}
        run: |
          set -euo pipefail
          dir="$RUNNER_TEMP/iterate_preflight_only"
          mkdir -p "$dir"
          status="$RUNNER_TEMP/iterate_status.txt"
          [ -f "$status" ] || echo 'preflight failed before attempts' > "$status"
          cp "$status" "$dir/iterate_status.txt"
          for src in preflight_llm_req.json preflight_llm_res.json preflight_llm_content.txt auth_body.json; do
            if [ -f "$RUNNER_TEMP/$src" ]; then
              cp "$RUNNER_TEMP/$src" "$dir/$src"
            fi
          done
          : > "$dir/prompt.txt"
          : > "$dir/codex_exec.log"
          : > "$dir/patch.diff"
          cp "$RUNNER_TEMP/preflight_llm_req.json" "$dir/llm_req.json" 2>/dev/null || true
          cp "$RUNNER_TEMP/preflight_llm_res.json" "$dir/llm_res.json" 2>/dev/null || true
          cp "$RUNNER_TEMP/preflight_llm_content.txt" "$dir/llm_content.txt" 2>/dev/null || true
          echo "preflight_dir=$dir" >> "$GITHUB_OUTPUT"
        id: preflight_diag

      - name: Upload preflight diagnostics artifact
        if: ${{ steps.preflight_diag.outputs.preflight_dir != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}-preflight
          path: ${{ steps.preflight_diag.outputs.preflight_dir }}
          if-no-files-found: warn
          retention-days: 14

      - name: Final summary
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        run: |
          status="$RUNNER_TEMP/iterate_status.txt"
          if [ -f "$status" ]; then
            echo '### Iterate status' >> "$GITHUB_STEP_SUMMARY"
            echo '```text' >> "$GITHUB_STEP_SUMMARY"
            tail -n 200 "$status" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

  deploy-iterate-pages:
    name: Deploy iterate diagnostics to Pages
    needs: iterate
    if: ${{ always() }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
      pages: write
      id-token: write
    environment:
      name: github-pages
    steps:
      - name: List diagnostics artifacts
        id: list_diag
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const runId = context.runId;
            const { data } = await github.rest.actions.listWorkflowRunArtifacts({
              owner,
              repo,
              run_id: runId,
              per_page: 100,
            });
            const artifacts = (data.artifacts || []).filter(a => !a.expired && a.name && a.name.startsWith('iterate-diag-'));
            core.setOutput('count', String(artifacts.length));
            core.setOutput('names', artifacts.map(a => a.name).join('\n'));

      - name: Checkout render helpers
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          sparse-checkout: |
            tools
            tools/render_iterate_pages.py
          sparse-checkout-cone-mode: false

      - name: Download diagnostics artifacts
        if: ${{ steps.list_diag.outputs.count != '0' }}
        uses: actions/download-artifact@v4
        with:
          pattern: iterate-diag-*
          path: ${{ runner.temp }}/downloaded-diag
          merge-multiple: false

      - name: Stage diagnostics into public directory
        run: |
          set -euo pipefail
          rm -rf public
          mkdir -p public
          if [ -d "$RUNNER_TEMP/downloaded-diag" ]; then
            for dir in "$RUNNER_TEMP"/downloaded-diag/*; do
              [ -d "$dir" ] || continue
              name=$(basename "$dir")
              dest="public/$name"
              mkdir -p "$dest"
              cp -R "$dir"/* "$dest"/ 2>/dev/null || true
            done
          fi
          touch public/.nojekyll

      - name: Generate diagnostics index
        env:
          NOTE: ${{ steps.list_diag.outputs.count == '0' && 'No iterate-diag-* artifacts were produced for this run.' || '' }}
        run: |
          set -euo pipefail
          python tools/render_iterate_pages.py public \
            --repo "${{ github.repository }}" \
            --sha "${{ github.sha }}" \
            --run-id "${{ github.run_id }}" \
            --attempt "${{ github.run_attempt }}" \
            --note "${NOTE}"

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to Pages
        id: deploy
        uses: actions/deploy-pages@v4

      - name: Summarize deployment
        run: |
          url='${{ steps.deploy.outputs.page_url }}'
          {
            echo '### Iterate diagnostics Pages'
            if [ -n "$url" ]; then
              echo "- Deployed: [$url]($url)"
            else
              echo '- Deployed: (no URL returned)'
            fi
            if [ -n "${{ steps.list_diag.outputs.names }}" ]; then
              echo '#### Included artifacts'
              echo '```'
              printf '%s\n' "${{ steps.list_diag.outputs.names }}"
              echo '```'
            else
              echo '- No iterate-diag-* artifacts were available; fallback page published.'
            fi
          } >> "$GITHUB_STEP_SUMMARY"
