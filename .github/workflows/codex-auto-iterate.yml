# yamllint disable rule:line-length rule:truthy rule:colons rule:document-start rule:empty-lines
# version: v2025-10-08.41 (Decide gate: here-doc JSON + env defaults; PR body unchanged)
# lineage: v39 â†’ tiny fix only in Decide gate

name: Codex - Auto Iterate on CI Failure

on:
  push:
    branches: ['**']
  workflow_dispatch: {}

permissions:
  actions: write
  contents: write
  pages: write
  id-token: write
  pull-requests: write

defaults:
  run:
    shell: bash

concurrency:
  group: codex-iterate-${{ github.sha }}
  cancel-in-progress: true

jobs:
  iterate:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MAX_ATTEMPTS: '4'
      OPENAI_MODEL: gpt-5-codex
      POLL_TIMEOUT_SECONDS: '1200'
      POLL_INTERVAL_SECONDS: '10'
    steps:
      - name: Debug event
        run: |
          echo "event=${{ github.event_name }}"
          echo "ref_name=${{ github.ref_name }}"
          echo "sha=${{ github.sha }}"
          echo "actor=${{ github.actor }}"
          echo "workflow=${{ github.workflow }}"
          echo "run_id=${{ github.run_id }}"

      - name: Checkout repo (latest)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize Git EOL for patching
        shell: pwsh
        run: |
          git config core.autocrlf false
          git config core.eol lf
          git config core.safecrlf warn

      - name: Auth probe (Responses API)
        id: auth
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ env.OPENAI_MODEL }}
        run: |
          set -euo pipefail
          ok_state="n/a"

          if [ -z "${OPENAI_API_KEY:-}" ]; then
            ok_state="false"
            echo "ok=false"      >> "$GITHUB_OUTPUT"
            echo "reason=no_key" >> "$GITHUB_OUTPUT"
            {
              echo "### Auth probe"
              echo
              echo "- key: MISSING"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          RESP="$RUNNER_TEMP/auth_body.json"
          http_code=0
          reason=""

          # First try: model as provided using input_text payload required by Responses API
          req1=`mktemp`
          {
            printf '{\n'
            printf '  "model": "%s",\n' "$OPENAI_MODEL"
            printf '  "input": [\n'
            printf '    {"role":"system","content":[{"type":"input_text","text":"Auth probe: expect 200"}]},\n'
            printf '    {"role":"user","content":[{"type":"input_text","text":"ping"}]}\n'
            printf '  ],\n'
            printf '  "max_output_tokens": 16\n'
            printf '}\n'
          } > "$req1"
          http_code=`curl -sS -o "$RESP" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$req1" || true`
          rm -f "$req1"
          reason="http_${http_code}"

          # Retry with lowercase slug on any non-200
          if [ "$http_code" != "200" ]; then
            lower_model=`printf '%s' "$OPENAI_MODEL" | tr 'A-Z' 'a-z'`
            if [ "$lower_model" != "$OPENAI_MODEL" ]; then
              req2=`mktemp`
              {
                printf '{\n'
                printf '  "model": "%s",\n' "$lower_model"
                printf '  "input": [\n'
                printf '    {"role":"system","content":[{"type":"input_text","text":"Auth probe retry: expect 200"}]},\n'
                printf '    {"role":"user","content":[{"type":"input_text","text":"ping"}]}\n'
                printf '  ],\n'
                printf '  "max_output_tokens": 16\n'
                printf '}\n'
              } > "$req2"
              http_code=`curl -sS -o "$RESP" -w "%{http_code}" \
                https://api.openai.com/v1/responses \
                -H "authorization: Bearer $OPENAI_API_KEY" \
                -H "content-type: application/json" \
                -d @"$req2" || true`
              rm -f "$req2"
              reason="retry_lowercase_http_${http_code}"
            fi
          fi

          if [ "$http_code" = "200" ]; then
            ok_state="true"
            echo "ok=true"   >> "$GITHUB_OUTPUT"
            echo "reason=ok" >> "$GITHUB_OUTPUT"
          else
            short=`jq -r '.error.message // empty' "$RESP" 2>/dev/null || true`
            if [ -n "$short" ]; then reason="$reason:$short"; fi
            ok_state="false"
            echo "ok=false"        >> "$GITHUB_OUTPUT"
            echo "reason=$reason"  >> "$GITHUB_OUTPUT"
          fi

          {
            echo "### Auth probe (Responses API)"
            echo
            echo "- model (env): ${OPENAI_MODEL}"
            echo "- http_code: ${http_code}"
            echo "- ok: ${ok_state}"
            echo "- reason: ${reason}"
            echo
            echo "Body (first 300 chars):"
            echo '```json'
            head -c 300 "$RESP" | sed 's/[^[:print:]\t]/?/g' || true
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Gather context
        id: ctx
        run: |
          set -euo pipefail
          branch="${{ github.ref_name }}"
          sha="${{ github.event.pull_request.head.sha || github.sha }}"
          run_id="${{ github.run_id }}"
          run_url="https://github.com/${{ github.repository }}/actions/runs/${run_id}"
          branch_slug=`echo "$branch" | tr ':/ ' '---'`
          echo "branch=$branch" >> "$GITHUB_OUTPUT"
          echo "branch_slug=$branch_slug" >> "$GITHUB_OUTPUT"
          echo "head_sha=$sha" >> "$GITHUB_OUTPUT"
          echo "run_id=$run_id" >> "$GITHUB_OUTPUT"
          echo "run_url=$run_url" >> "$GITHUB_OUTPUT"

      - name: Write local Codex context
        shell: pwsh
        run: |
          $Head = "${{ github.event.pull_request.head.sha || github.sha }}"
          $Base = "${{ github.event.pull_request.base.sha || '' }}"
          if (-not $Base) { $Base = (git rev-parse HEAD~1).Trim() }
          New-Item -ItemType Directory -Path .codex -Force | Out-Null
          git diff --name-only --diff-filter=ACMRT $Base $Head | Set-Content -Encoding UTF8 .codex/changed_files.txt
          $wf = Get-ChildItem '.github/workflows' -Filter *.yml -File -ErrorAction SilentlyContinue |
                ForEach-Object { $_.FullName.Replace($PWD,'').TrimStart('\').Replace('\','/') }
          $ctx = [pscustomobject]@{
            repo='${{ github.repository }}'; event='${{ github.event_name }}'
            head_sha=$Head; base_sha=$Base; ref='${{ github.ref }}'
            run_id='${{ github.run_id }}'; run_attempt='${{ github.run_attempt }}'
            runner_os=$env:RUNNER_OS; shell='pwsh'
            apply_patch = (Resolve-Path 'tools/apply_patch.py' -ErrorAction SilentlyContinue).Path
            workflows = $wf
          }
          $ctx | ConvertTo-Json -Depth 6 | Set-Content -Encoding UTF8 .codex/context.json

      - name: Poll ALL workflow runs for this commit
        id: poll
        uses: actions/github-script@v7
        env:
          HEAD_SHA: ${{ github.event.pull_request.head.sha || github.sha }}
          POLL_TIMEOUT_SECONDS: ${{ env.POLL_TIMEOUT_SECONDS }}
          POLL_INTERVAL_SECONDS: ${{ env.POLL_INTERVAL_SECONDS }}
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const sha   = process.env.HEAD_SHA || context.sha;
            const selfRunId = String(context.runId || "");
            const selfName  = (context.workflow || "").toLowerCase();
            const deadline = Date.now() + (parseInt(process.env.POLL_TIMEOUT_SECONDS||"1200")*1000);
            const interval = parseInt(process.env.POLL_INTERVAL_SECONDS||"10")*1000;

            async function listRunsForSha() {
              const { data } = await github.rest.actions.listWorkflowRunsForRepo({
                owner, repo, head_sha: sha, per_page: 100
              });
              return (data.workflow_runs || []);
            }

            function filterNotSelf(runs) {
              return runs.filter(r =>
                String(r.id) !== selfRunId &&
                (r.name||"").toLowerCase() !== selfName
              );
            }

            let lastSeen = [];
            let chosen = null;
            while (Date.now() < deadline) {
              let runs = await listRunsForSha();
              runs = filterNotSelf(runs);
              lastSeen = runs.map(r => ({id:r.id, name:r.name, status:r.status, conclusion:r.conclusion}));

              if (runs.length === 0) {
                await new Promise(r => setTimeout(r, interval));
                continue;
              }

              const incomplete = runs.filter(r => r.status !== "completed");
              if (incomplete.length > 0) {
                await new Promise(r => setTimeout(r, interval));
                continue;
              }

              const runsWithJobs = [];
              for (const r of runs) {
                const { data } = await github.rest.actions.listJobsForWorkflowRun({
                  owner, repo, run_id: r.id, per_page: 100
                });
                const hasFailJob = (data.jobs || []).some(j => (j.conclusion||"") === "failure");
                runsWithJobs.push({ ...r, hasFailJob });
              }

              // Prefer runs with a failed job; some runs are 'cancelled' despite job failures.
              const failedJob = runsWithJobs.find(r => r.hasFailJob);
              const failure = runsWithJobs.find(r => (r.conclusion||"") === "failure");
              const needsAction = runsWithJobs.find(r => ["timed_out", "action_required"].includes(r.conclusion||""));
              const cancelled = runsWithJobs.find(r => (r.conclusion||"") === "cancelled");
              const nonSuccess = runsWithJobs.find(r => (r.conclusion||"") !== "success");
              chosen = failedJob || failure || needsAction || cancelled || nonSuccess || runsWithJobs[0];
              break;
            }

            if (!chosen) {
              core.setOutput("found_any", "false");
              core.setOutput("all_completed", "false");
              core.setOutput("any_non_success", "true");
              core.setOutput("summary_json", JSON.stringify(lastSeen));
            } else {
              core.setOutput("found_any", "true");
              core.setOutput("all_completed", "true");
              const anyNonSucc = lastSeen.some(r => (r.conclusion||"") !== "success");
              core.setOutput("any_non_success", String(anyNonSucc));
              core.setOutput("summary_json", JSON.stringify(lastSeen));
              core.setOutput("picked_id", String(chosen.id));
              core.setOutput("picked_name", chosen.name||"");
              core.setOutput("picked_status", chosen.status||"");
              core.setOutput("picked_conclusion", chosen.conclusion||"");
            }

      - name: Fetch failing run artifact (structured)
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: struct
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          api="https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID_PICKED}/artifacts"
          meta="$RUNNER_TEMP/artifacts.json"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" -H "Accept: application/vnd.github+json" "$api" -o "$meta" || true
          # Pick an artifact likely containing structured CI results
          name=`jq -r '.artifacts[].name' "$meta" 2>/dev/null | grep -E -i 'ndjson|summary_raw|self.?test|ci[-_]?result|first.?error|test[-_]?logs|diag' | head -n 1 || true`
          if [ -z "$name" ] || [ "$name" = "null" ]; then
            echo "artifact_name=" >> "$GITHUB_OUTPUT"
            echo "path=" >> "$GITHUB_OUTPUT"
            echo "extract_dir=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          id=`jq -r --arg n "$name" '.artifacts[] | select(.name==$n) | .id' "$meta" 2>/dev/null || true`
          if [ -z "$id" ] || [ "$id" = "null" ]; then
            echo "artifact_name=" >> "$GITHUB_OUTPUT"
            echo "path=" >> "$GITHUB_OUTPUT"
            echo "extract_dir=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          zipfile="$RUNNER_TEMP/struct.zip"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" -L \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$id/zip" -o "$zipfile" || true
          dest="$RUNNER_TEMP/struct"
          mkdir -p "$dest"
          unzip -q "$zipfile" -d "$dest" || true
          echo "extract_dir=$dest" >> "$GITHUB_OUTPUT"
          out="$RUNNER_TEMP/ci_structured.txt"
          : > "$out"
          # Prefer *.ndjson; else summary_raw*.txt; else any *.json with errors
          nd=`find "$dest" -type f -name '*.ndjson' | head -n 1 || true`
          if [ -n "$nd" ]; then
            jq -rc 'select((.level=="error") or (.status=="fail") or (.conclusion=="failure") or (.type=="error")) | . | {job:(.job//.workflow//"unknown"),step:(.step//"unknown"),file:(.file//"unknown"),line:(.line//null),msg:(.msg//.message//.error//.detail//"") } | @json' "$nd" | head -n 1 > "$out" || true
          fi
          if [ ! -s "$out" ]; then
            sr=`find "$dest" -type f -iname 'summary_raw*' -o -iname '*first*error*' -o -iname '*ci*result*.json' | head -n 1 || true`
            if [ -n "$sr" ]; then
              head -n 120 "$sr" > "$out" || true
            fi
          fi
          if [ -s "$out" ]; then
            # record artifact name so the context digest can cite the source
            echo "artifact_name=$name" >> "$GITHUB_OUTPUT"
            echo "path=$out" >> "$GITHUB_OUTPUT"
          else
            echo "artifact_name=" >> "$GITHUB_OUTPUT"
            echo "path=" >> "$GITHUB_OUTPUT"
            # Preserve extract_dir for downstream consumers even if parsing failed
            echo "extract_dir=$dest" >> "$GITHUB_OUTPUT"
          fi

      - name: Collect NDJSON sources
        if: ${{ steps.poll.outputs.picked_id != '' }}
        shell: pwsh
        run: |
          $candidates = @('ci_test_results.ndjson','~test-results.ndjson')
          $searchRoots = @("$env:RUNNER_TEMP/struct", "$env:RUNNER_TEMP", (Get-Location).Path) `
            | Where-Object { $_ -and (Test-Path $_) }
          $hit = $null
          foreach ($root in $searchRoots) {
            $probe = Get-ChildItem -Path $root -Recurse -File -Include $candidates -ErrorAction SilentlyContinue | Select-Object -First 1
            if ($probe) { $hit = $probe; break }
          }
          if ($hit) {
            Copy-Item $hit.FullName "ci_test_results.ndjson" -Force
            Copy-Item $hit.FullName "tests~test-results.ndjson" -Force
            "iterate-collector: collected=$($hit.FullName)" | Out-File -Append -Encoding ascii "$env:GITHUB_STEP_SUMMARY"
          } else {
            "iterate-collector: collected=none" | Out-File -Append -Encoding ascii "$env:GITHUB_STEP_SUMMARY"
          }

      - name: Fetch failing run logs (tail)
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: logtail
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          zipfile="$RUNNER_TEMP/other_run_logs.zip"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            -L "https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID_PICKED}/logs" \
            -o "$zipfile" || true
          extract_dir="$RUNNER_TEMP/logs_extract"
          mkdir -p "$extract_dir"
          unzip -q "$zipfile" -d "$extract_dir" || true
          OUT="$RUNNER_TEMP/failing_log_tail.txt"
          : > "$OUT"
          find "$extract_dir" -type f -name '*.txt' -printf "%s %p\n" > "$RUNNER_TEMP/logsizes.txt" || true
          sort -nr "$RUNNER_TEMP/logsizes.txt" | awk 'NR==1{print $2}' > "$RUNNER_TEMP/largest.txt" || true
          if [ -s "$RUNNER_TEMP/largest.txt" ]; then
            candidate=`cat "$RUNNER_TEMP/largest.txt"`
            if [ -f "$candidate" ]; then
              tail -n 200 "$candidate" > "$OUT" || true
            fi
          fi
          manifest="$RUNNER_TEMP/logs_manifest.txt"
          : > "$manifest"
          if [ -d "$extract_dir" ]; then
            find "$extract_dir" -type f -printf '%P\t%f\t%k\n' | sort > "$manifest" || true
          fi
          if [ ! -s "$manifest" ]; then
            rm -f "$manifest"
          fi
          echo "path=$OUT" >> "$GITHUB_OUTPUT"
          echo "extract_dir=$extract_dir" >> "$GITHUB_OUTPUT"
          if [ -f "$manifest" ]; then
            echo "manifest=$manifest" >> "$GITHUB_OUTPUT"
          else
            echo "manifest=" >> "$GITHUB_OUTPUT"
          fi

      - name: Fetch failing job metadata
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: jobmeta
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
          REPO_SLUG: ${{ github.repository }}
        run: |
          set -euo pipefail
          run_id="${RUN_ID_PICKED:-}"
          jobs_json="$RUNNER_TEMP/picked_jobs.json"
          rm -f "$jobs_json"
          if [ -n "$run_id" ]; then
            curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${REPO_SLUG}/actions/runs/${run_id}/jobs?per_page=100" \
              -o "$jobs_json" || true
          fi
          failed_id=""
          failed_name=""
          if [ -s "$jobs_json" ]; then
            failed_id=`jq -r '.jobs[] | select(.conclusion=="failure") | .id' "$jobs_json" 2>/dev/null | head -n 1 || true`
            failed_name=`jq -r '.jobs[] | select(.conclusion=="failure") | .name' "$jobs_json" 2>/dev/null | head -n 1 || true`
          else
            jobs_json=""
          fi
          if [ "$failed_id" = "null" ]; then failed_id=""; fi
          if [ "$failed_name" = "null" ]; then failed_name=""; fi
          echo "failed_id=$failed_id" >> "$GITHUB_OUTPUT"
          echo "failed_name=$failed_name" >> "$GITHUB_OUTPUT"
          if [ -n "$jobs_json" ] && [ -f "$jobs_json" ]; then
            echo "jobs_path=$jobs_json" >> "$GITHUB_OUTPUT"
          else
            echo "jobs_path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Focus failing job logs
        if: ${{ steps.logtail.outputs.extract_dir != '' && (steps.jobmeta.outputs.failed_id != '' || steps.jobmeta.outputs.failed_name != '') }}
        id: logfocus
        env:
          EXTRACT_DIR: ${{ steps.logtail.outputs.extract_dir }}
          JOB_ID: ${{ steps.jobmeta.outputs.failed_id }}
          JOB_NAME: ${{ steps.jobmeta.outputs.failed_name }}
        run: |
          set -euo pipefail
          extract_dir="${EXTRACT_DIR:-}"
          if [ -z "$extract_dir" ] || [ ! -d "$extract_dir" ]; then
            echo "path=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          ident_primary="${JOB_ID:-}"
          ident_secondary="${JOB_NAME:-}"
          if [ -z "$ident_primary" ] && [ -z "$ident_secondary" ]; then
            echo "path=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          focus_path="$RUNNER_TEMP/failing_job_focus.txt"
          python tools/focus_logs.py "$EXTRACT_DIR" "$focus_path" "$JOB_ID" "$JOB_NAME"
          if [ -s "$focus_path" ]; then
            echo "path=$focus_path" >> "$GITHUB_OUTPUT"
          else
            rm -f "$focus_path"
            echo "path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Stage failure snippets for prompt
        if: ${{ steps.poll.outputs.picked_id != '' }}
        env:
          STRUCT_PATH: ${{ steps.struct.outputs.path }}
          STRUCT_DIR: ${{ steps.struct.outputs.extract_dir }}
          LOGFOCUS_PATH: ${{ steps.logfocus.outputs.path }}
        run: |
          set -euo pipefail
          mkdir -p .codex/fail
          if [ -n "${STRUCT_PATH:-}" ] && [ -f "$STRUCT_PATH" ]; then
            cp "$STRUCT_PATH" .codex/fail/ci_structured.txt
          fi
          if [ -n "${LOGFOCUS_PATH:-}" ] && [ -f "$LOGFOCUS_PATH" ]; then
            cp "$LOGFOCUS_PATH" .codex/fail/failing_job_focus.txt
          fi
          first_json=""
          if [ -n "${STRUCT_DIR:-}" ] && [ -d "$STRUCT_DIR" ]; then
            first_json=`find "$STRUCT_DIR" -type f -name 'first_failure.json' | head -n 1 || true`
          fi
          if [ -n "$first_json" ] && [ -f "$first_json" ]; then
            id=$(jq -r '(.id // .name // "") | gsub("[\r\n]+"; " ")' "$first_json" 2>/dev/null || true)
            desc=$(jq -r '(.desc // .description // .message // "") | gsub("[\r\n]+"; " ")' "$first_json" 2>/dev/null || true)
            source=$(jq -r '(.source // .file // .path // "") | gsub("[\r\n]+"; " ")' "$first_json" 2>/dev/null || true)
            if [ -z "$id" ]; then id="unknown"; fi
            if [ -z "$desc" ]; then desc="unknown"; fi
            if [ -z "$source" ]; then source="unknown"; fi
            printf 'id=%s | %s (source=%s)\n' "$id" "$desc" "$source" > .codex/fail/first_failure.txt
          fi

      - name: Ensure NDJSON sources for gate
        if: ${{ steps.poll.outputs.picked_id != '' }}
        shell: pwsh
        env:
          STRUCT_DIR: ${{ steps.struct.outputs.extract_dir }}
        run: |
          $workspace = Convert-Path '.'
          $structDir = $env:STRUCT_DIR
          $diagRoot = ''
          if ($structDir) {
            try {
              $diagRoot = Split-Path -LiteralPath (Convert-Path $structDir) -Parent
            } catch {
              $diagRoot = ''
            }
          }
          # derived requirement: gate previously skipped iterate because tests~test-results.ndjson
          # and ci_test_results.ndjson were missing. Reuse a helper so both filenames are
          # synthesized or copied before the Decide gate runs.
          & "$env:GITHUB_WORKSPACE/tools/ensure_ndjson_sources.ps1" -Workspace $workspace -StructDir $structDir -DiagRoot $diagRoot

      - name: Decide gate (iterate vs skip)
        id: gate
        env:
          FOUND_ANY: ${{ steps.poll.outputs.found_any }}
          ALL_COMPLETED: ${{ steps.poll.outputs.all_completed }}
          ANY_NON_SUCCESS: ${{ steps.poll.outputs.any_non_success }}
          SUMMARY_JSON: ${{ steps.poll.outputs.summary_json }}
          NDJSON_FOUND: ${{ env.GATE_NDJSON_FOUND }}
          NDJSON_SOURCE: ${{ env.GATE_NDJSON_SOURCE }}
          NDJSON_MISSING: ${{ env.GATE_NDJSON_MISSING }}
        run: |
          set -euo pipefail
          # Safe defaults so -u doesn't explode if outputs are unset
          FOUND_ANY="${FOUND_ANY:-}"
          ALL_COMPLETED="${ALL_COMPLETED:-}"
          ANY_NON_SUCCESS="${ANY_NON_SUCCESS:-}"
          NDJSON_FOUND="${NDJSON_FOUND:-}"
          NDJSON_SOURCE="${NDJSON_SOURCE:-}"
          NDJSON_MISSING="${NDJSON_MISSING:-}"

          should_iterate=false
          reason=""
          if [ "${FOUND_ANY}" != "true" ]; then
            should_iterate=true
            reason="no_runs_or_timeout"
          else
            if [ "${ALL_COMPLETED}" != "true" ]; then
              should_iterate=true
              reason="runs_not_completed_timeout"
            else
              if [ "${ANY_NON_SUCCESS}" = "true" ]; then
                should_iterate=true
                reason="one_or_more_runs_failed"
              else
                should_iterate=false
                reason="all_success"
              fi
            fi
          fi
          echo "should_iterate=${should_iterate}" >> "$GITHUB_OUTPUT"
          echo "reason=${reason}" >> "$GITHUB_OUTPUT"

          {
            echo "### Poll summary"
            echo '```json'
            printf '%s\n' "$SUMMARY_JSON"
            echo '```'
            echo
            echo "### Iterate NDJSON sources"
            if [ "$NDJSON_FOUND" = "true" ]; then
              echo "- found: ${NDJSON_SOURCE:-unknown}"
            else
              missing_note="${NDJSON_MISSING:-tests~test-results.ndjson;ci_test_results.ndjson}"
              echo "- missing: ${missing_note}"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Load/Update attempt counter
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: attempts
        env:
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
        run: |
          set -euo pipefail
          attempts=0
          GH_TOKEN="${{ github.token }}"
          owner_repo="${{ github.repository }}"
          branch_slug="${{ steps.ctx.outputs.branch_slug }}"
          curl -sS -H "Authorization: Bearer $GH_TOKEN" \
            "https://api.github.com/repos/${owner_repo}/actions/artifacts?per_page=100" > artifacts_all.json
          id=`jq -r --arg n "iterate-state-$branch_slug" '.artifacts[] | select(.name==$n and ((.expired // false) | not)) | .id' artifacts_all.json | head -n 1 || true`
          stored_sha=""
          if [ -n "$id" ] && [ "$id" != "null" ]; then
            curl -sSL -H "Authorization: Bearer $GH_TOKEN" -L \
              "https://api.github.com/repos/${owner_repo}/actions/artifacts/$id/zip" \
              -o state.zip || true
            mkdir -p state && unzip -q state.zip -d state || true
            attempts_raw=`jq -r '.attempts // 0' state/iterate_state.json 2>/dev/null || echo 0`
            stored_sha=`jq -r '.head_sha // ""' state/iterate_state.json 2>/dev/null || echo ''`
            if printf '%s' "$attempts_raw" | grep -Eq '^[0-9]+$'; then
              attempts="$attempts_raw"
            else
              attempts=0
            fi
          fi
          head_sha="${HEAD_SHA:-}"
          if [ -n "$stored_sha" ] && [ -n "$head_sha" ] && [ "$stored_sha" != "$head_sha" ]; then
            attempts=0
          fi
          nextfile="$RUNNER_TEMP/next.txt"
          echo "$attempts" | awk '{print $1+1}' > "$nextfile"
          next=`cat "$nextfile"`
          if [ "$next" -gt "${MAX_ATTEMPTS}" ]; then
            echo "stop=true" >> "$GITHUB_OUTPUT"
            echo "stop_reason=Max attempts reached (${MAX_ATTEMPTS})" >> "$GITHUB_OUTPUT"
            echo "previous=$attempts" >> "$GITHUB_OUTPUT"
            echo "next=$attempts" >> "$GITHUB_OUTPUT"
            echo "remaining=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          remaining=$(( ${MAX_ATTEMPTS:-0} - next ))
          if [ "$remaining" -lt 0 ]; then
            remaining=0
          fi
          echo "stop=false" >> "$GITHUB_OUTPUT"
          echo "previous=$attempts" >> "$GITHUB_OUTPUT"
          echo "next=$next" >> "$GITHUB_OUTPUT"
          echo "remaining=$remaining" >> "$GITHUB_OUTPUT"

      - name: Record iterate status
        if: always()
        env:
          GATE: ${{ steps.gate.outputs.should_iterate }}
          GATE_REASON: ${{ steps.gate.outputs.reason }}
          AUTH_OK: ${{ steps.auth.outputs.ok }}
          AUTH_REASON: ${{ steps.auth.outputs.reason }}
          STOP: ${{ steps.attempts.outputs.stop }}
          STOP_REASON: ${{ steps.attempts.outputs.stop_reason }}
          REMAINING: ${{ steps.attempts.outputs.remaining }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, pathlib


          def _parse_bool(value: str):
              if value == "true":
                  return True
              if value == "false":
                  return False
              return None


          def _parse_int(value: str):
              if not value:
                  return None
              try:
                  return int(value)
              except ValueError:
                  return None


          gate = os.environ.get("GATE", "")
          gate_reason = os.environ.get("GATE_REASON", "")
          auth_ok = os.environ.get("AUTH_OK", "")
          auth_reason = os.environ.get("AUTH_REASON", "")
          stop = os.environ.get("STOP", "")
          stop_reason = os.environ.get("STOP_REASON", "")
          remaining = os.environ.get("REMAINING", "")

          attempted = gate == "true" and auth_ok == "true" and stop != "true"

          status = {
              "attempted": attempted,
              "gate": _parse_bool(gate),
              "auth_ok": _parse_bool(auth_ok),
              "attempts_left": _parse_int(remaining),
          }

          runner_temp = pathlib.Path(os.environ["RUNNER_TEMP"])
          status_path = runner_temp / "iterate_status.json"
          status_path.write_text(json.dumps(status, indent=2) + "\n", encoding="utf-8")

          why_reason = None
          summary_path = os.environ.get("GITHUB_STEP_SUMMARY")

          if not attempted:
              gate_val = _parse_bool(gate)
              auth_val = _parse_bool(auth_ok)
              if gate_val is False:
                  detail = gate_reason or "gate reason unavailable"
                  why_reason = f"skipped: gate=false ({detail})"
              elif stop == "true":
                  detail = stop_reason or "no stop reason"
                  why_reason = f"skipped: attempts exhausted ({detail})"
              elif auth_val is False or auth_ok == "":
                  detail = auth_reason or "auth unavailable"
                  why_reason = f"skipped: auth failure ({detail})"

              if summary_path and stop == "true":
                  detail = stop_reason or "no stop reason"
                  message = (
                      "### Iterate gate\n"
                      "- skipping due to gate with 0 attempts left ({detail})\n"
                  ).format(detail=detail)
                  with open(summary_path, "a", encoding="utf-8") as handle:
                      handle.write(message)

          why_path = runner_temp / "why_no_diff.txt"
          if why_reason:
              why_path.write_text(why_reason + "\n", encoding="utf-8")
          elif why_path.exists():
              why_path.unlink()
          PY

      - name: Discover diagnostics root
        id: diag_discover
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          diag=""
          search_dirs=("$GITHUB_WORKSPACE" "$RUNNER_TEMP")
          for base in "${search_dirs[@]}"; do
            if [ -z "$base" ] || [ ! -d "$base" ]; then
              continue
            fi
            candidate=$(find "$base" -type d -path '*/_artifacts/batch-check' -print -quit 2>/dev/null || true)
            if [ -n "$candidate" ]; then
              # derived requirement: keep DIAG pointing at the diagnostics root that holds
              # batchcheck_failing.txt alongside the _artifacts directory so downstream
              # prompt builders resolve both correctly.
              diag="$(dirname "$(dirname "$candidate")")"
              break
            fi
          done
          if [ -z "$diag" ] && [ -d "$GITHUB_WORKSPACE/diag" ]; then
            diag="$GITHUB_WORKSPACE/diag"
          fi
          if [ -n "$diag" ]; then
            echo "DIAG_DIR=$diag" >> "$GITHUB_ENV"
            # derived requirement: reviewer flagged that env-expressions resolve before the
            # discovery step executes. Surface the path as a step output so later steps can
            # reference the resolved directory without clobbering it to empty.
            printf 'path=%s\n' "$diag" >> "$GITHUB_OUTPUT"
            {
              echo "### Diagnostics root"
              echo "- path: $diag"
            } >> "$GITHUB_STEP_SUMMARY"
          else
            echo "DIAG_DIR=" >> "$GITHUB_ENV"
            printf 'path=\n' >> "$GITHUB_OUTPUT"
            {
              echo "### Diagnostics root"
              echo "- path: not found"
            } >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Build model repo bundle
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        shell: pwsh
        env:
          ITERATE_REDACT_PATTERN: '(?i)(secret|token|password|apikey|key|sk-[A-Za-z0-9]{20,})'
        run: |
          & "$env:GITHUB_WORKSPACE/tools/make_model_repo_bundle.ps1" -OutZip "$env:RUNNER_TEMP/repo_context.zip" -MaxMB 25

      - name: Upload repo bundle
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        id: upload_repo_bundle
        shell: bash
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "error: OPENAI_API_KEY is missing" >&2
            exit 1
          fi
          zip_path="$RUNNER_TEMP/repo_context.zip"
          if [ ! -f "$zip_path" ]; then
            echo "error: repo bundle not found at $zip_path" >&2
            exit 1
          fi
          resp="$(curl -sS -X POST https://api.openai.com/v1/files \
            -H "Authorization: Bearer $OPENAI_API_KEY" \
            -F purpose="assistants" \
            -F file="@${zip_path}")"
          file_id="$(python -c 'import json, sys; data=json.loads(sys.stdin.read()); fid=data.get("id"); if not fid: raise SystemExit("missing file id"); print(fid)' <<< "$resp")"
          if [ -z "$file_id" ]; then
            echo "error: failed to parse file_id from upload response" >&2
            echo "$resp" >&2
            exit 1
          fi
          printf 'file_id=%s\n' "$file_id" >> "$GITHUB_OUTPUT"
          {
            echo '### Model repo bundle'
            echo "- file_id: $file_id"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Build prompt
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        id: prompt
        shell: pwsh
        env:
          REPO: ${{ github.repository }}
          BRANCH: ${{ steps.ctx.outputs.branch }}
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
          ATTEMPT_NEXT: ${{ steps.attempts.outputs.next }}
          STRUCT_PATH: ${{ steps.struct.outputs.path }}
          LOGFOCUS_PATH: ${{ steps.logfocus.outputs.path }}
          LOGTAIL_PATH: ${{ steps.logtail.outputs.path }}
          DIAG: ${{ steps.diag_discover.outputs.path }}
          ITERATE_REDACT_PATTERN: '(?i)(secret|token|password|apikey|key|sk-[A-Za-z0-9]{20,})'
          REDACT_PLACEHOLDER: '***'
        run: |
          & "$env:GITHUB_WORKSPACE/tools/diag/build_prompt.ps1"

      - name: Prompt preview
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        run: |
          echo "### Prompt (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```text' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "${{ steps.prompt.outputs.path }}" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Ask model for patch (Responses API)
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: llm
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ env.OPENAI_MODEL }}
        run: |
          set -euo pipefail
          # Professional note: tee stdout/stderr so publish_diag can fall back to this
          # local copy when GitHub's run-logs zip is still propagating (per maintainer request
          # to "add a fallback: capture stdout/stderr from the iterate job into a file").
          ITER_LOG="$RUNNER_TEMP/iterate_step.log"
          : > "$ITER_LOG"
          exec > >(tee -a "$ITER_LOG") 2>&1
          REQ="$RUNNER_TEMP/llm_req.json"
          RES="$RUNNER_TEMP/llm_res.json"
          OUTTXT="$RUNNER_TEMP/llm_content.txt"
          PROMPT_FILE="${{ steps.prompt.outputs.path }}"
          REPO_FILE_ID="${{ steps.upload_repo_bundle.outputs.file_id }}"
          if [ -z "$REPO_FILE_ID" ]; then
            echo "error: repo bundle file_id is missing" >&2
            exit 1
          fi
          jq -Rs '.' < "$PROMPT_FILE" > "$RUNNER_TEMP/prompt.json"
          MAX_OUTPUT_TOKENS_INITIAL=2000
          # gpt-5-codex supports responses up to 16k output tokens; keep retries within ceiling.
          MAX_OUTPUT_TOKENS_CEIL=16000
          RETRY_OUTPUT_TOKENS=$(( MAX_OUTPUT_TOKENS_INITIAL * 2 ))
          if [ "$RETRY_OUTPUT_TOKENS" -gt "$MAX_OUTPUT_TOKENS_CEIL" ]; then
            RETRY_OUTPUT_TOKENS=$MAX_OUTPUT_TOKENS_CEIL
          fi
          write_request() {
            local tokens="$1"
            # derived requirement: adopt files-first iterate strategy so Responses can unzip
            # the curated repo bundle via code_interpreter rather than bloating the prompt.
            python -c 'import json, sys, pathlib; model, prompt_path, file_id, tokens, req_path = sys.argv[1:]; tokens = int(tokens); prompt = pathlib.Path(prompt_path).read_text(encoding="utf-8"); payload = {"model": model, "tools": [{"type": "code_interpreter"}], "input": [{"role": "system", "content": [{"type": "input_text", "text": "You are an expert software engineer that proposes precise, minimal unified diffs."}]}, {"role": "user", "content": [{"type": "input_text", "text": prompt}, {"type": "input_file", "file_id": file_id}]}], "max_output_tokens": tokens}; pathlib.Path(req_path).write_text(json.dumps(payload), encoding="utf-8")' "$OPENAI_MODEL" "$PROMPT_FILE" "$REPO_FILE_ID" "$tokens" "$REQ"
          }
          write_request "$MAX_OUTPUT_TOKENS_INITIAL"
          http_code=`curl -sS -o "$RES" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$REQ" || true`
          attempt_summary="first request"
          first_incomplete_reason=""
          final_response_attempt="none"
          if [ "$http_code" = "200" ]; then
            first_incomplete_reason=`jq -r '.incomplete_details.reason // empty' "$RES" 2>/dev/null || true`
            final_response_attempt="first"
            if [ "$first_incomplete_reason" = "max_output_tokens" ] && [ "$RETRY_OUTPUT_TOKENS" -gt "$MAX_OUTPUT_TOKENS_INITIAL" ]; then
              attempt_summary="retry after max_output_tokens (tokens=${RETRY_OUTPUT_TOKENS})"
              write_request "$RETRY_OUTPUT_TOKENS"
              http_code=`curl -sS -o "$RES" -w "%{http_code}" \
                https://api.openai.com/v1/responses \
                -H "authorization: Bearer $OPENAI_API_KEY" \
                -H "content-type: application/json" \
                -d @"$REQ" || true`
              if [ "$http_code" = "200" ]; then
                final_response_attempt="second"
              else
                final_response_attempt="none"
              fi
            fi
          fi
          echo "http_code=$http_code"
          echo "http_code=$http_code" >> "$GITHUB_OUTPUT"
          {
            echo "- completion attempt: $attempt_summary"
            if [ -n "$first_incomplete_reason" ]; then
              echo "- first attempt incomplete_reason: $first_incomplete_reason"
            fi
            if [ "$final_response_attempt" != "none" ]; then
              echo "- final response produced by: ${final_response_attempt} attempt"
            else
              echo "- final response produced by: none (http ${http_code})"
            fi
            echo
          } >> "$GITHUB_STEP_SUMMARY"
          echo "### LLM body (first 300 chars)" >> "$GITHUB_STEP_SUMMARY"
          echo '```json' >> "$GITHUB_STEP_SUMMARY"
          head -c 300 "$RES" | sed 's/[^[:print:]\t]/?/g' >> "$GITHUB_STEP_SUMMARY" || true
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          err=`jq -r '.error.message // empty' "$RES" 2>/dev/null || true`
          if [ -n "$err" ]; then echo "**error:** $err" >> "$GITHUB_STEP_SUMMARY"; fi
          # Responses API prefers output_text; fall back to first textual content item if absent
          jq -r '(
            .output_text //
            (.output[]? | .content[]? | select(.type=="output_text") | .text) //
            (.output[0]? | .content[0]? | .text // "")
          )' "$RES" > "$OUTTXT" || true
          echo "### LLM response (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "$OUTTXT" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

          usage_json='null'
          if [ -s "$RES" ]; then
            usage_json=$(jq -c '{prompt_tokens: (.usage.prompt_tokens // null), completion_tokens: (.usage.completion_tokens // null), total_tokens: (.usage.total_tokens // null)}' "$RES" 2>/dev/null || echo 'null')
          fi
          jq -n \
            --arg status "$http_code" \
            --arg model "$OPENAI_MODEL" \
            --arg attempt_summary "$attempt_summary" \
            --arg final_attempt "$final_response_attempt" \
            --arg incomplete "$first_incomplete_reason" \
            --argjson usage "$usage_json" \
            '{
              http_status: (if ($status|tonumber? // null) != null then ($status|tonumber) else $status end),
              model: $model,
              attempt_summary: $attempt_summary,
              final_response_attempt: (if $final_attempt == "none" then null else $final_attempt end),
              incomplete_reason: (if $incomplete == "" then null else $incomplete end),
              usage: (if $usage == null then null else $usage end)
            }' > "$RUNNER_TEMP/response.json"

          WHY_FILE="$RUNNER_TEMP/why_no_diff.txt"
          reason=""
          if [ "$http_code" != "200" ]; then
            reason="http_error_${http_code}"
          else
            if [ ! -s "$OUTTXT" ]; then
              reason="empty response"
            elif ! grep -q '```diff' "$OUTTXT"; then
              reason="diff fence not found"
            fi
          fi
          if [ -n "$reason" ]; then
            printf '%s\n' "$reason" > "$WHY_FILE"
          else
            rm -f "$WHY_FILE"
          fi

      - name: Extract model rationale (optional)
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: rationale
        run: |
          set -euo pipefail
          CONTENT="$RUNNER_TEMP/llm_content.txt"
          OUT="$RUNNER_TEMP/llm_rationale.txt"
          : > "$OUT"
          if [ -f "$CONTENT" ]; then
            # capture optional summary_text fence (cap at 10 lines)
            awk '/^```summary_text[[:space:]]*$/{inside=1;next} /^```$/{if(inside){exit}} inside{print}' "$CONTENT" | head -n 10 > "$OUT" || true
          fi
          if [ -s "$OUT" ]; then
            echo "rationale_path=$OUT" >> "$GITHUB_OUTPUT"
            {
              echo "### Model rationale"
              cat "$OUT"
            } >> "$GITHUB_STEP_SUMMARY"
          else
            echo "rationale_path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Ensure iterate failure bundle assets
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        env:
          STRUCT_PATH: ${{ steps.struct.outputs.path }}
          LOGFOCUS_PATH: ${{ steps.logfocus.outputs.path }}
        run: |
          set -euo pipefail
          fail_dir=".codex/fail"
          mkdir -p "$fail_dir"
          if [ -n "${STRUCT_PATH:-}" ] && [ -f "$STRUCT_PATH" ]; then
            cp "$STRUCT_PATH" "$fail_dir/ci_structured.txt"
          fi
          if [ -n "${LOGFOCUS_PATH:-}" ] && [ -f "$LOGFOCUS_PATH" ]; then
            cp "$LOGFOCUS_PATH" "$fail_dir/failing_job_focus.txt"
          fi
          if [ ! -f "$RUNNER_TEMP/prompt.txt" ]; then
            : > "$RUNNER_TEMP/prompt.txt"
          fi

      - name: Extract fenced diff
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: diff
        run: |
          set -euo pipefail
          CONTENT="$RUNNER_TEMP/llm_content.txt"
          DIFF_OUT="$RUNNER_TEMP/patch.diff"
          awk 'BEGIN{f=0} /```diff/ && f==0 {f=1; next} /```/ && f==1 {f=2} f==1 {print}' "$CONTENT" > "$DIFF_OUT" || true
          if [ ! -s "$DIFF_OUT" ]; then
            echo "# no changes" > "$DIFF_OUT"
          fi
          echo "diff_path=$DIFF_OUT" >> "$GITHUB_OUTPUT"
          echo "### Extracted diff (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```diff' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "$DIFF_OUT" >> "$GITHUB_STEP_SUMMARY" || true
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Note diff availability
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        run: |
          set -euo pipefail
          diff_path="${{ steps.diff.outputs.diff_path }}"
          why_file="$RUNNER_TEMP/why_no_diff.txt"
          if [ -z "$diff_path" ] || [ ! -f "$diff_path" ]; then
            exit 0
          fi
          if grep -Fxq '# no changes' "$diff_path"; then
            if [ ! -s "$why_file" ]; then
              printf '%s\n' "model returned # no changes" > "$why_file"
            fi
          else
            rm -f "$why_file"
          fi

      - name: Apply model patch (robust)
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: apply
        shell: bash
        run: |
          set -euo pipefail
          diff="$RUNNER_TEMP/patch.diff"
          log="$RUNNER_TEMP/patch.apply.log"
          : > "$log"
          echo "log_path=$log" >> "$GITHUB_OUTPUT"
          if [ -f "$diff" ] && grep -Fxq '# no changes' "$diff"; then
            # Professional note: respect "model returned # no changes" so downstream steps
            # skip needless apply/PR work and surface the diagnostic reason instead.
            echo "changed=false" >> "$GITHUB_OUTPUT"
            echo "model returned # no changes; skipping apply" >> "$log"
            exit 0
          fi
          if [ ! -s "$diff" ]; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
            echo "no diff" >> "$log"
            exit 0
          fi
          if git apply --check --whitespace=fix "$diff" 2>>"$log"; then
            echo "git apply --check succeeded; applying patch" >>"$log"
            git apply --whitespace=fix "$diff" 2>>"$log"
            echo "changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "git apply --check failed; invoking tools/apply_patch.py" >>"$log"
            python3 tools/apply_patch.py --input "$diff" >>"$log" 2>&1 || true
            if ! git diff --quiet; then
              echo "changed=true" >> "$GITHUB_OUTPUT"
            else
              echo "changed=false" >> "$GITHUB_OUTPUT"
              echo "fallback produced no tree changes" >>"$log"
            fi
          fi

      - name: Synthesize failing summary
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        shell: pwsh
        run: |
          New-Item -ItemType Directory -Path .codex -Force | Out-Null
          $root = Join-Path '.codex' 'fail'
          $out  = Join-Path '.codex' 'failing_summary.md'
          New-Item -ItemType Directory -Path $root -Force | Out-Null

          # Professional note: Join-Path keeps the summary portable across ubuntu-latest and any future Windows runners.
          $lines = @(
            '# Failing context',
            '- run: ${{ github.run_id }} attempt ${{ github.run_attempt }}',
            '- ref: `${{ github.ref }}`  sha: `${{ github.sha }}`',
            '',
            '## First errors (grep)',
            ''
          )

          $resolvedRoot = (Resolve-Path $root).Path

          # Professional note: allow regex matching so the summary surfaces the first error-class message from each log file.
          Get-ChildItem -Path $root -Recurse -File -ErrorAction SilentlyContinue |
            Select-String -Pattern 'ERROR|Exception|Traceback|failed' -List |
            Select-Object -First 40 |
            ForEach-Object {
              $rel = [System.IO.Path]::GetRelativePath($resolvedRoot, $_.Path) -replace '\\','/'
              $lines += ('* {0}:{1}: {2}' -f $rel, $_.LineNumber, $_.Line.Trim())
            }

          $lines += @("", "## Tail of failing job log", '```')

          $tailLog = Get-ChildItem -Path $root -Recurse -File -Include '*fail*.log*','*job*.log*' -ErrorAction SilentlyContinue |
            Sort-Object Length -Descending |
            Select-Object -First 1

          if ($null -ne $tailLog) {
            Get-Content -Tail 200 $tailLog.FullName | ForEach-Object { $lines += $_ }
          } else {
            $lines += '<no fail logs captured>'
          }

          $lines += '```'

          ($lines -join "`n") | Set-Content -Encoding UTF8 $out

      - name: Stage iterate diagnostics artifact
        id: diag_stage
        env:
          DIAG_DIR: ${{ steps.diag_discover.outputs.path }}
          REPO_FILE_ID: ${{ steps.upload_repo_bundle.outputs.file_id }}
        run: |
          set -euo pipefail
          iter_dir="$GITHUB_WORKSPACE/iterate"
          rm -rf "$iter_dir"
          mkdir -p "$iter_dir"
          temp_dir="$iter_dir/_temp"
          mkdir -p "$temp_dir"

          placeholder="$iter_dir/README.txt"
          {
            printf 'Iterate diagnostics placeholder\n'
            printf 'No iterate payloads were captured for this run.\n'
          } >"$placeholder"

          # Professional note: create redacted request/response bundles and metadata per maintainer checklist.
          model="${{ env.OPENAI_MODEL }}"
          printf 'model=%s\n' "${model:-n/a}" > "$iter_dir/model.txt"

          endpoint="https://api.openai.com/v1/responses"
          printf 'endpoint=%s\n' "$endpoint" > "$iter_dir/endpoint.txt"

          sdk_file="$iter_dir/sdk.txt"
          {
            printf 'node=%s\n' "$(node --version 2>/dev/null || echo n/a)"
            printf 'npm=%s\n' "$(npm --version 2>/dev/null || echo n/a)"
            printf 'python=%s\n' "$(python --version 2>/dev/null || echo n/a)"
            pwsh_ver="$(pwsh -NoLogo -NoProfile -Command '$PSVersionTable.PSVersion.ToString()' 2>/dev/null || echo n/a)"
            printf 'pwsh=%s\n' "$pwsh_ver"
            printf 'curl=%s\n' "$(curl --version 2>/dev/null | head -n1 | tr -d '\r' || echo n/a)"
          } > "$sdk_file"

          http_status="${{ steps.llm.outputs.http_code }}"
          if [ -z "$http_status" ]; then
            http_status="n/a"
          fi
          printf '%s\n' "$http_status" > "$iter_dir/http_status.txt"

          req_raw="$RUNNER_TEMP/llm_req.json"
          res_raw="$RUNNER_TEMP/llm_res.json"
          content_txt="$RUNNER_TEMP/llm_content.txt"
          diff_path="${{ steps.diff.outputs.diff_path }}"
          apply_log="${{ steps.apply.outputs.log_path }}"
          fallback_log="$RUNNER_TEMP/patch.apply.log"

          sanitize(){
            local input="$1"
            local output="$2"
            local limit="$3"
            shift 3
            if [ -f "$input" ]; then
              # derived requirement: reviewer flagged that standalone OpenAI tokens
              # like ``sk-...`` appear without preceding keywords; extend the pattern
              # so diagnostics never leak those values.
              python tools/sanitize_iterate_payload.py \
                --input "$input" \
                --output "$output" \
                --truncate "$limit" \
                --redact-pattern '(?i)(secret|token|password|apikey|key|sk-[A-Za-z0-9]{20,})' \
                --placeholder '***' \
                "$@"
            fi
          }

          copy_into_temp(){
            local source="$1"
            local name="$2"
            if [ -f "$source" ]; then
              cp "$source" "$temp_dir/$name"
            fi
          }

          sanitize "$req_raw" "$iter_dir/request.redacted.json" 100000 || true
          sanitize "$res_raw" "$iter_dir/response.json" 200000 \
            --why-output "$RUNNER_TEMP/why_no_diff.txt" \
            --diff-path "$diff_path" \
            --response-text "$content_txt" \
            --diag-root "${DIAG_DIR:-}" || true
          copy_into_temp "$iter_dir/request.redacted.json" "request.redacted.json"
          copy_into_temp "$iter_dir/response.json" "response.json"

          if [ -n "${REPO_FILE_ID:-}" ]; then
            printf 'file_id=%s\n' "$REPO_FILE_ID" > "$iter_dir/repo_bundle_file_id.txt"
            copy_into_temp "$iter_dir/repo_bundle_file_id.txt" "repo_bundle_file_id.txt"
          fi

          tokens_file="$iter_dir/tokens.txt"
          if [ -f "$res_raw" ]; then
            prompt=$(jq -r '.usage.prompt_tokens // empty' "$res_raw" 2>/dev/null || echo '')
            completion=$(jq -r '.usage.completion_tokens // empty' "$res_raw" 2>/dev/null || echo '')
            total=$(jq -r '.usage.total_tokens // empty' "$res_raw" 2>/dev/null || echo '')
            {
              printf 'prompt=%s\n' "${prompt:-n/a}"
              printf 'completion=%s\n' "${completion:-n/a}"
              printf 'total=%s\n' "${total:-n/a}"
            } > "$tokens_file"
          else
            printf 'prompt=n/a\ncompletion=n/a\ntotal=n/a\n' > "$tokens_file"
          fi
          copy_into_temp "$tokens_file" "tokens.txt"

          decision_file="$iter_dir/decision.txt"
          decision="no-diff"
          reason=""
          if [ "$http_status" != "200" ] && [ "$http_status" != "n/a" ]; then
            decision="error-$http_status"
            reason="HTTP failure"
          else
            if [ -n "$diff_path" ] && [ -f "$diff_path" ] && grep -q '^# no changes$' "$diff_path"; then
              decision="no-diff"
            elif [ "${{ steps.apply.outputs.changed }}" = "true" ]; then
              decision="diff-applied"
            elif [ -n "$diff_path" ] && [ -f "$diff_path" ]; then
              decision="diff-failed"
              reason="apply returned ${{ steps.apply.outputs.changed }}"
            else
              decision="error-missing-diff"
              reason="diff not generated"
            fi
          fi
          {
            printf 'decision=%s\n' "$decision"
            if [ -n "$reason" ]; then
              printf 'reason=%s\n' "$reason"
            fi
          } > "$decision_file"

          if [ -n "$diff_path" ] && [ -f "$diff_path" ]; then
            cp "$diff_path" "$iter_dir/patch.diff"
            copy_into_temp "$iter_dir/patch.diff" "patch.diff"
          fi

          if [ -n "$apply_log" ] && [ -f "$apply_log" ]; then
            cp "$apply_log" "$iter_dir/patch.apply.log"
          else
            printf 'apply log unavailable\n' | tee "$iter_dir/patch.apply.log" > "$fallback_log"
            apply_log="$fallback_log"
          fi
          copy_into_temp "$iter_dir/patch.apply.log" "patch.apply.log"

          if [ ! -f "$fallback_log" ]; then
            printf 'apply log unavailable\n' > "$fallback_log"
          fi

          codex_log="$GITHUB_WORKSPACE/codex_exec.log"

          if [ -f "$content_txt" ]; then
            {
              printf '### iterate exec log\n'
              printf 'Captured from Responses API output.\n\n'
              cat "$content_txt"
            } > "$iter_dir/exec.log"
            cp "$iter_dir/exec.log" "$codex_log"
          else
            printf 'no exec content captured\n' > "$iter_dir/exec.log"
            cp "$iter_dir/exec.log" "$codex_log"
          fi
          copy_into_temp "$iter_dir/exec.log" "exec.log"

          if [ -f "$RUNNER_TEMP/prompt.txt" ]; then
            cp "$RUNNER_TEMP/prompt.txt" "$iter_dir/prompt.txt"
            copy_into_temp "$iter_dir/prompt.txt" "prompt.txt"
          fi

          if [ -f "$RUNNER_TEMP/auth_body.json" ]; then
            sanitize "$RUNNER_TEMP/auth_body.json" "$iter_dir/auth_probe.json" 100000 || true
          fi
          copy_into_temp "$iter_dir/auth_probe.json" "auth_probe.json"

          iter_stdout="$RUNNER_TEMP/iterate_step.log"
          if [ -f "$iter_stdout" ]; then
            # Professional note: surface the raw job stream when GitHub's run-logs zip
            # is unavailable so the published bundle still exposes iterate stdout/stderr.
            cp "$iter_stdout" "$iter_dir/job.log"
          fi
          copy_into_temp "$iter_dir/job.log" "job.log"

          if [ -f "$RUNNER_TEMP/why_no_diff.txt" ]; then
            cp "$RUNNER_TEMP/why_no_diff.txt" "$iter_dir/why_no_diff.txt"
            copy_into_temp "$iter_dir/why_no_diff.txt" "why_no_diff.txt"
          fi

          if [ -f "$RUNNER_TEMP/iterate_status.json" ]; then
            cp "$RUNNER_TEMP/iterate_status.json" "$iter_dir/iterate_status.json"
            copy_into_temp "$iter_dir/iterate_status.json" "iterate_status.json"
          fi

          summary_file="${GITHUB_STEP_SUMMARY:-}"
          if [ -n "$summary_file" ] && [ -f "$summary_file" ]; then
            cp "$summary_file" "$iter_dir/job-summary.md"
          fi

          files_found=$(find "$iter_dir" -type f 2>/dev/null | wc -l || echo 0)
          if [ "$files_found" -gt 0 ]; then
            rm -f "$placeholder"
          fi

          printf 'dir=%s\n' "$iter_dir" >> "$GITHUB_OUTPUT"
          printf 'codex_log=%s\n' "$codex_log" >> "$GITHUB_OUTPUT"

      - name: Collect iterate artifact paths
        if: always()
        id: iter_paths
        env:
          DIAG_DIR: ${{ steps.diag_stage.outputs.dir }}
          DIAG_CODEX_LOG: ${{ steps.diag_stage.outputs.codex_log }}
          PATCH_LOG: ${{ runner.temp }}/patch.apply.log
        run: |
          set -euo pipefail
          paths=".codex/**"
          if [ -n "${DIAG_DIR:-}" ]; then
            paths="$paths"$'\n'"${DIAG_DIR}/**"
          fi
          if [ -n "${DIAG_CODEX_LOG:-}" ]; then
            paths="$paths"$'\n'"${DIAG_CODEX_LOG}"
          fi
          paths="$paths"$'\n'"${PATCH_LOG}"
          if [ -n "$paths" ]; then
            {
              printf 'list<<EOF_ITER\n'
              printf '%s\n' "$paths"
              printf 'EOF_ITER\n'
            } >> "$GITHUB_OUTPUT"
          fi

      - name: Upload iterate logs artifact
        if: ${{ always() && steps.llm.outcome != 'skipped' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-logs-${{ github.run_id }}-${{ github.run_attempt }}
          path: |
            .codex/**
            ${{ steps.diag_stage.outputs.dir }}/**
          include-hidden-files: true
          if-no-files-found: error
          retention-days: 7

      - name: Build context digest
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: digest
        env:
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
          RUN_NAME: ${{ steps.poll.outputs.picked_name }}
          RUN_CONCLUSION: ${{ steps.poll.outputs.picked_conclusion }}
          STRUCT_PATH: ${{ steps.struct.outputs.path }}
          STRUCT_NAME: ${{ steps.struct.outputs.artifact_name }}
          LOG_PATH: ${{ steps.logtail.outputs.path }}
          LOGFOCUS_PATH: ${{ steps.logfocus.outputs.path }}
          JOB_ID_RAW: ${{ steps.jobmeta.outputs.failed_id }}
          JOB_NAME_RAW: ${{ steps.jobmeta.outputs.failed_name }}
        run: |
          set -euo pipefail
          run_id="${RUN_ID_PICKED:-}"
          run_name="${RUN_NAME:-}"
          run_conclusion="${RUN_CONCLUSION:-}"
          job_id="${JOB_ID_RAW:-}"
          job_name="${JOB_NAME_RAW:-}"

          struct_path="${STRUCT_PATH:-}"
          struct_name="${STRUCT_NAME:-}"
          log_path="${LOG_PATH:-}"
          focus_path="${LOGFOCUS_PATH:-}"
          context_path=""
          context_source=""
          if [ -n "$struct_path" ] && [ -s "$struct_path" ]; then
            context_path="$struct_path"
            context_source="$struct_name"
            if [ -z "$context_source" ]; then
              context_source="structured-artifact"
            fi
          elif [ -n "$focus_path" ] && [ -s "$focus_path" ]; then
            context_path="$focus_path"
            context_source="focused-job-log"
          elif [ -n "$log_path" ] && [ -s "$log_path" ]; then
            context_path="$log_path"
            context_source="failing-job-log"
          fi

          first_line=""
          if [ -n "$context_path" ] && [ -f "$context_path" ]; then
            # sanitize the first line from the selected context source
            first_line=`head -n 1 "$context_path" | sed 's/[^[:print:]\t]/?/g' || true`
          fi

          path_display="$context_path"
          if [ -z "$path_display" ]; then
            path_display="N/A"
          fi
          source_display="$context_source"
          if [ -z "$source_display" ]; then
            source_display="N/A"
          fi

          digest_file="$RUNNER_TEMP/context_digest.txt"
          {
            echo "### Context digest"
            if [ -n "$run_id" ] || [ -n "$run_name" ] || [ -n "$run_conclusion" ]; then
              printf -- '- run: %s "%s" â€” %s\n' "$run_id" "$run_name" "$run_conclusion"
            else
              echo "- run:"
            fi
            if [ -n "$job_id" ] || [ -n "$job_name" ]; then
              printf -- '- job: %s "%s"\n' "$job_id" "$job_name"
            else
              echo "- job:"
            fi
            printf -- '- source: %s\n' "$source_display"
            printf -- '- path: %s\n' "$path_display"
            printf -- '- first-line: %s\n' "$first_line"
          } > "$digest_file"

          {
            echo
            cat "$digest_file"
          } >> "$GITHUB_STEP_SUMMARY"

          echo "digest_file=$digest_file" >> "$GITHUB_OUTPUT"

      - name: Build PR body file
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: pr_body
        env:
          SUMMARY_JSON: ${{ steps.poll.outputs.summary_json }}
          AUTH_OK_RAW: ${{ steps.auth.outputs.ok }}
          AUTH_REASON_RAW: ${{ steps.auth.outputs.reason }}
          BRANCH_NAME: ${{ steps.ctx.outputs.branch }}
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
          GATE_REASON: ${{ steps.gate.outputs.reason }}
          CONTEXT_DIGEST_PATH: ${{ steps.digest.outputs.digest_file }}
          RATIONALE_PATH: ${{ steps.rationale.outputs.rationale_path }}
        run: |
          set -euo pipefail
          BODY=".github/ITERATE_PR_BODY.md"
          mkdir -p .github
          summary="${SUMMARY_JSON:-}"
          if [ -z "$summary" ] || [ "$summary" = "null" ]; then
            summary='[]'
          fi

          auth_ok="${AUTH_OK_RAW:-}"
          if [ -z "$auth_ok" ]; then
            auth_ok='false'
          fi

          auth_reason_raw="${AUTH_REASON_RAW:-}"
          auth_reason_raw="${auth_reason_raw//$'\r'/ }"
          auth_reason_raw="${auth_reason_raw//$'\n'/ }"
          if [ -z "$auth_reason_raw" ]; then
            auth_reason_raw='n/a'
          fi

          branch_name="${BRANCH_NAME:-unknown}"
          head_sha="${HEAD_SHA:-unknown}"
          gate_reason="${GATE_REASON:-unknown}"

          {
            printf '## Codex iteration (push-poll ALL workflows)\n\n'
            printf -- '- Branch: `%s` @ %s\n' "$branch_name" "$head_sha"
            printf -- '- Gate reason: %s\n\n' "$gate_reason"
            printf '### Polled runs\n'
            printf '```json\n'
            printf '%s\n' "$summary"
            printf '```\n\n'
            printf '### Auth probe\n'
            printf -- '- ok: %s (reason: %s)\n' "$auth_ok" "$auth_reason_raw"
          } > "$BODY"

          context_digest_file="${CONTEXT_DIGEST_PATH:-}"
          if [ -n "$context_digest_file" ] && [ -s "$context_digest_file" ]; then
            printf '\n' >> "$BODY"
            cat "$context_digest_file" >> "$BODY"
            printf '\n' >> "$BODY"
          fi

          if [ -f "$RUNNER_TEMP/prompt.txt" ]; then
            {
              printf '\n### Prompt (first 200 lines)\n'
              printf '```text\n'
              head -n 200 "$RUNNER_TEMP/prompt.txt" || true
              printf '```\n'
            } >> "$BODY"
          fi

          if [ -f "$RUNNER_TEMP/patch.diff" ]; then
            {
              printf '\n### Extracted diff (first 200 lines)\n'
              printf '```diff\n'
              head -n 200 "$RUNNER_TEMP/patch.diff" || true
              printf '```\n'
            } >> "$BODY"
          fi

          rationale_file="${RATIONALE_PATH:-}"
          if [ -n "$rationale_file" ] && [ -s "$rationale_file" ]; then
            {
              printf '\n### Model rationale\n'
              cat "$rationale_file"
              printf '\n'
            } >> "$BODY"
          fi

          echo "body_path=$BODY" >> "$GITHUB_OUTPUT"

      - name: Create PR (if edits)
        if: ${{ steps.apply.outputs.changed == 'true' }}
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "codex: iterate on CI failure (attempt ${{ steps.attempts.outputs.next }}/${{ env.MAX_ATTEMPTS }})"
          branch: codex/ci-fix-${{ steps.ctx.outputs.branch_slug }}
          base: ${{ steps.ctx.outputs.branch }}
          title: "Codex: iterate on CI failure â€“ ${{ steps.ctx.outputs.branch }}"
          body-path: ${{ steps.pr_body.outputs.body_path }}
          labels: codex,ci-fix,automerge-candidate

      - name: Save attempt state
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        env:
          ATTEMPTS: ${{ steps.attempts.outputs.next }}
          RUN_ID: ${{ steps.ctx.outputs.run_id }}
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
        run: |
          mkdir -p state_out
          printf '{\n' > state_out/iterate_state.json
          printf '  "attempts": "%s",\n' "$ATTEMPTS" >> state_out/iterate_state.json
          printf '  "run_id": "%s",\n' "$RUN_ID" >> state_out/iterate_state.json
          printf '  "head_sha": "%s"\n' "$HEAD_SHA" >> state_out/iterate_state.json
          printf '}\n' >> state_out/iterate_state.json

      - name: Upload attempt state
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-state-${{ steps.ctx.outputs.branch_slug }}
          path: state_out
          if-no-files-found: warn
          retention-days: 30

      - name: Mark job neutral if we got this far
        if: ${{ always() }}
        run: echo "::notice title=iterate::Job completed - forcing neutral so logs persist"


  publish_diag:
    name: Publish diagnostics to Pages
    needs: [iterate]
    if: ${{ always() }}
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    permissions:
      contents: read
      pages: write
      id-token: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Prep site directories
        id: prep
        shell: pwsh
        run: |
          $RunId = "${{ github.run_id }}"
          $Attempt = "${{ github.run_attempt }}"
          $SiteRoot = Join-Path $PWD 'site'
          if (Test-Path $SiteRoot) { Remove-Item -Recurse -Force $SiteRoot }
          New-Item -ItemType Directory -Path $SiteRoot | Out-Null
          $DiagRoot = Join-Path $SiteRoot 'diag'
          New-Item -ItemType Directory -Path $DiagRoot | Out-Null
          $Diag = Join-Path $DiagRoot "$RunId-$Attempt"
          New-Item -ItemType Directory -Path $Diag | Out-Null
          $Artifacts = Join-Path $Diag '_artifacts'
          New-Item -ItemType Directory -Path $Artifacts | Out-Null
          # Professional note: .nojekyll keeps GitHub Pages from stripping the leading underscore
          # directories that we rely on to surface raw diagnostics.
          New-Item -ItemType File -Path (Join-Path $SiteRoot '.nojekyll') -Force | Out-Null
          # Professional note: duplicate .nojekyll at the per-run diag root so direct links into
          # underscore-prefixed folders (e.g., _artifacts) stay browsable when users open the
          # diagnostics bundle without hitting the site root first.
          New-Item -ItemType File -Path (Join-Path $Diag '.nojekyll') -Force | Out-Null
          $short = "${{ github.sha }}"
          if ($short.Length -gt 7) { $short = $short.Substring(0,7) }
          echo "SITE=$SiteRoot" >> $env:GITHUB_OUTPUT
          echo "DIAG=$Diag" >> $env:GITHUB_OUTPUT
          echo "ARTIFACTS=$Artifacts" >> $env:GITHUB_OUTPUT
          echo "SHORTSHA=$short" >> $env:GITHUB_OUTPUT

      - name: Download iterate artifacts
        if: ${{ always() }}
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: iterate-logs-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ steps.prep.outputs.ARTIFACTS }}/iterate

      - name: Record iterate artifact status
        shell: pwsh
        run: |
          $Artifacts = "${{ steps.prep.outputs.ARTIFACTS }}"
          $Iter = Join-Path $Artifacts 'iterate'
          $sentinel = Join-Path $Artifacts 'MISSING.txt'
          # Professional note: _artifacts/ mirrors producer payloads exactly; the sentinel documents gaps for external analysts.
          $files = @()
          if (Test-Path $Iter) {
            $files = Get-ChildItem -Path $Iter -Recurse -File -ErrorAction SilentlyContinue
          }
          if (-not $files -or $files.Count -eq 0) {
            "iterate artifact missing or empty" | Out-File -Append -Encoding UTF8 $sentinel
          }

      - name: Fetch batch-check artifacts
        id: fetch_batch
        shell: pwsh
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          $ArtifactsRoot = "${{ steps.prep.outputs.ARTIFACTS }}"
          $BatchRoot = Join-Path $ArtifactsRoot 'batch-check'
          New-Item -ItemType Directory -Path $BatchRoot -Force | Out-Null
          $statusPath = Join-Path $BatchRoot 'STATUS.txt'
          $missingPath = Join-Path $ArtifactsRoot 'MISSING.txt'
          # Professional note: correlate the batch-check workflow by commit SHA so the diagnostics bundle mirrors
          # the matching self-test run; missing runs append a sentinel entry so downstream readers understand why.

          $repoParts = "${{ github.repository }}".Split('/')
          if ($repoParts.Count -ne 2) {
            'repository parsing failed' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: repository parse error' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          if (-not $env:GH_TOKEN) {
            'GH_TOKEN unavailable; batch-check artifacts skipped.' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: GH_TOKEN unavailable' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          $owner = $repoParts[0]
          $repo  = $repoParts[1]
          $base = "https://api.github.com/repos/$owner/$repo"
          $headers = @{
            Accept      = 'application/vnd.github+json'
            Authorization = "Bearer $env:GH_TOKEN"
            'User-Agent' = 'iterate-publish'
          }

          $workflow = $null
          try {
            $workflow = Invoke-RestMethod -Uri "$base/actions/workflows/batch-check.yml" -Headers $headers -ErrorAction Stop
          } catch {
            $response = $_.Exception.Response
            $statusCode = $null
            if ($response -and $response.StatusCode) {
              $statusCode = [int]$response.StatusCode.value__
            }

            if ($statusCode -eq 404) {
              # Professional note: fall back to enumerating the workflow catalog so forks with relocated files still resolve batch-check.
              try {
                $catalog = Invoke-RestMethod -Uri "$base/actions/workflows" -Headers $headers -ErrorAction Stop
                $workflow = @($catalog.workflows | Where-Object { $_.path -and $_.path.ToLower().EndsWith('batch-check.yml') })[0]
              } catch {
                "workflow lookup failed (fallback enumeration): $($_.Exception.Message)" | Set-Content -Encoding UTF8 $statusPath
                "batch-check artifact lookup failed: fallback enumeration error: $($_.Exception.Message)" | Out-File -Append -Encoding UTF8 $missingPath
                return
              }
            } else {
              "workflow lookup failed: $($_.Exception.Message)" | Set-Content -Encoding UTF8 $statusPath
              "batch-check artifact lookup failed: $($_.Exception.Message)" | Out-File -Append -Encoding UTF8 $missingPath
              return
            }
          }

          if (-not $workflow) {
            'workflow lookup failed: batch-check workflow not found' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: batch-check workflow not found' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          if (-not $workflow.id) {
            'workflow id missing' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: workflow id missing' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          $pollSeconds = 20
          $deadline = [DateTime]::UtcNow.AddMinutes(15)
          $headSha = "${{ github.event.pull_request.head.sha || github.sha }}"
          $run = $null
          while ([DateTime]::UtcNow -lt $deadline) {
            try {
              $runs = Invoke-RestMethod -Uri "$base/actions/workflows/$($workflow.id)/runs?per_page=20&head_sha=$headSha" -Headers $headers -ErrorAction Stop
            } catch {
              "list runs failed: $($_.Exception.Message)" | Set-Content -Encoding UTF8 $statusPath
              return
            }

            $candidates = @($runs.workflow_runs | ForEach-Object { $_ }) | Where-Object { $_ -and $_.status -eq 'completed' }
            if ($candidates.Count -gt 0) {
              $run = $candidates | Sort-Object run_attempt -Descending | Select-Object -First 1
              break
            }

            Start-Sleep -Seconds $pollSeconds
          }

          if (-not $run) {
            'no completed run found before timeout' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: no completed run for this commit' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          $meta = [ordered]@{
            workflow_id = $workflow.id
            run_id = $run.id
            run_attempt = $run.run_attempt
            status = $run.status
            conclusion = $run.conclusion
            html_url = $run.html_url
          }
          $meta | ConvertTo-Json -Depth 6 | Set-Content -Encoding UTF8 (Join-Path $BatchRoot 'run.json')
          "run_id=$($run.id)" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding ascii -Append
          "run_attempt=$($run.run_attempt)" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding ascii -Append
          if ($run.html_url) {
            "run_url=$($run.html_url)" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding ascii -Append
          }

          try {
            $artifacts = Invoke-RestMethod -Uri "$base/actions/runs/$($run.id)/artifacts?per_page=100" -Headers $headers -ErrorAction Stop
          } catch {
            "artifact list failed: $($_.Exception.Message)" | Set-Content -Encoding UTF8 $statusPath
            return
          }

          if (-not $artifacts.artifacts) {
            'no artifacts published by batch-check' | Set-Content -Encoding UTF8 $statusPath
            'batch-check artifact lookup failed: no artifacts in run' | Out-File -Append -Encoding UTF8 $missingPath
            return
          }

          Remove-Item -LiteralPath $statusPath -ErrorAction SilentlyContinue

          foreach ($artifact in $artifacts.artifacts) {
            if (-not $artifact -or $artifact.expired) { continue }
            $safeName = ($artifact.name -replace '[^A-Za-z0-9_.-]', '_')
            $dest = Join-Path $BatchRoot $safeName
            New-Item -ItemType Directory -Path $dest -Force | Out-Null
            $zipPath = Join-Path $env:RUNNER_TEMP ("batch-" + $artifact.id + '.zip')
            try {
              Invoke-WebRequest -Uri $artifact.archive_download_url -Headers $headers -OutFile $zipPath -ErrorAction Stop
              Expand-Archive -LiteralPath $zipPath -DestinationPath $dest -Force
            } catch {
              "download failed: $($artifact.name) -> $($_.Exception.Message)" | Out-File -Append -Encoding UTF8 $statusPath
            } finally {
              Remove-Item -LiteralPath $zipPath -ErrorAction SilentlyContinue
            }
          }

      - name: Summarize failing tests
        shell: bash
        env:
          DIAG: ${{ steps.prep.outputs.DIAG }}
        run: |
          python tools/diag/ndjson_fail_list.py

      - name: Download workflow logs
        shell: pwsh
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          $Diag = "${{ steps.prep.outputs.DIAG }}"
          $repoParts = "${{ github.repository }}".Split('/')
          if ($repoParts.Count -ne 2) { return }
          if (-not $env:GH_TOKEN) {
            'GH_TOKEN unavailable; workflow logs skipped.' | Set-Content -Encoding UTF8 (Join-Path $Diag 'logs-note.txt')
            return
          }

          $owner = $repoParts[0]
          $repo  = $repoParts[1]
          $headers = @{
            Accept      = 'application/vnd.github+json'
            Authorization = "Bearer $env:GH_TOKEN"
            'User-Agent' = 'iterate-publish'
          }

          # Professional note: maintainers requested "add a short retry loop ... before writing
          # the missing sentinel", so we wrap Invoke-WebRequest with a bounded retry helper.
          function Download-WithRetry {
            param(
              [Parameter(Mandatory=$true)][string]$Uri,
              [Parameter(Mandatory=$true)][string]$Destination,
              [Parameter(Mandatory=$true)][hashtable]$Headers,
              [int]$Attempts = 3,
              [int]$DelaySeconds = 5
            )

            for ($i = 1; $i -le $Attempts; $i++) {
              try {
                Invoke-WebRequest -Uri $Uri -Headers $Headers -OutFile $Destination -ErrorAction Stop
                return $true
              } catch {
                if ($i -ge $Attempts) {
                  return $false
                }
                Start-Sleep -Seconds $DelaySeconds
              }
            }
          }

          $logDir = Join-Path $Diag 'logs'
          New-Item -ItemType Directory -Path $logDir -Force | Out-Null

          $iterateZip = Join-Path $logDir ("iterate-${{ github.run_id }}-${{ github.run_attempt }}.zip")
          $iterateSentinel = Join-Path $logDir 'iterate.MISSING.txt'
          # Professional note: log downloads remain optional; when they fail we emit explicit sentinel files so the
          # published bundle still explains what is missing without failing the workflow.
          $iterateLogUri = "https://api.github.com/repos/$owner/$repo/actions/runs/${{ github.run_id }}/logs"
          if (-not (Download-WithRetry -Uri $iterateLogUri -Destination $iterateZip -Headers $headers)) {
            "iterate log download failed after retries: $iterateLogUri" | Out-File -Encoding UTF8 -FilePath (Join-Path $logDir 'iterate-log-error.txt')
          }
          if (-not (Test-Path $iterateZip)) {
            'iterate log archive missing' | Set-Content -Encoding UTF8 $iterateSentinel
          } else {
            $info = Get-Item -LiteralPath $iterateZip
            if (-not $info -or $info.Length -eq 0) {
              'iterate log archive empty' | Set-Content -Encoding UTF8 $iterateSentinel
            }
          }

          $batchRunId = "${{ steps.fetch_batch.outputs.run_id }}"
          if ($batchRunId) {
            $batchAttempt = "${{ steps.fetch_batch.outputs.run_attempt }}"
            if (-not $batchAttempt) { $batchAttempt = '1' }
            $batchZip = Join-Path $logDir ("batch-check-$batchRunId-$batchAttempt.zip")
            $batchSentinel = Join-Path $logDir 'batch-check.MISSING.txt'
            $batchLogUri = "https://api.github.com/repos/$owner/$repo/actions/runs/$batchRunId/logs"
            if (-not (Download-WithRetry -Uri $batchLogUri -Destination $batchZip -Headers $headers)) {
              "batch-check log download failed after retries: $batchLogUri" | Out-File -Encoding UTF8 -FilePath (Join-Path $logDir 'batch-check-log-error.txt')
            }
            if (-not (Test-Path $batchZip)) {
              'batch-check log archive missing' | Set-Content -Encoding UTF8 $batchSentinel
            } else {
              $bInfo = Get-Item -LiteralPath $batchZip
              if (-not $bInfo -or $bInfo.Length -eq 0) {
                'batch-check log archive empty' | Set-Content -Encoding UTF8 $batchSentinel
              }
            }
          } else {
            $missing = Join-Path $logDir 'batch-check.MISSING.txt'
            'batch-check logs not located for this commit' | Set-Content -Encoding UTF8 $missing
          }

      - name: Capture repository snapshot
        shell: pwsh
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          $Diag = "${{ steps.prep.outputs.DIAG }}"
          $short = "${{ steps.prep.outputs.SHORTSHA }}"
          if (-not $short) {
            $short = "${{ github.sha }}"
            if ($short.Length -gt 7) { $short = $short.Substring(0,7) }
          }
          git ls-tree -r --name-only HEAD | Set-Content -Encoding UTF8 (Join-Path $Diag 'repo-tree.txt')
          $repoDir = Join-Path $Diag 'repo'
          New-Item -ItemType Directory -Path $repoDir -Force | Out-Null
          $repoZip = Join-Path $repoDir ("repo-$short.zip")
          $repoMissing = Join-Path $repoDir 'repo.MISSING.txt'
          # Professional note: the repo/ folder mirrors GitHub's zipball for this commit so analysts can download
          # an authenticated snapshot without signing into Actions.
          $parts = "${{ github.repository }}".Split('/')
          if ($parts.Count -eq 2 -and $env:GH_TOKEN) {
            $owner = $parts[0]
            $repo = $parts[1]
            $headers = @{
              Accept       = 'application/vnd.github+json'
              Authorization = "Bearer $env:GH_TOKEN"
              'User-Agent'  = 'iterate-publish'
            }
            $zipUrl = "https://api.github.com/repos/$owner/$repo/zipball/${{ github.sha }}"
            try {
              Invoke-WebRequest -Uri $zipUrl -Headers $headers -OutFile $repoZip -ErrorAction Stop
            } catch {
              "repo zip download failed: $($_.Exception.Message)" | Set-Content -Encoding UTF8 $repoMissing
            }
          } else {
            'repo zip download skipped: missing GH token or repo metadata' | Set-Content -Encoding UTF8 $repoMissing
          }
          if (Test-Path $repoZip) {
            $repoExtract = Join-Path $repoDir 'files'
            if (Test-Path $repoExtract) { Remove-Item -LiteralPath $repoExtract -Recurse -Force -ErrorAction SilentlyContinue }
            New-Item -ItemType Directory -Path $repoExtract -Force | Out-Null
            try {
              # Professional note: maintainers asked for "an unzipped set alongside/sub page" so analysts can
              # browse without downloading the archive; we unpack the commit zip alongside the original bundle.
              Expand-Archive -LiteralPath $repoZip -DestinationPath $repoExtract -Force
            } catch {
              "repo unzip failed: $($_.Exception.Message)" | Set-Content -Encoding UTF8 (Join-Path $repoDir 'repo-unpack-error.txt')
            }
          }
          Get-ChildItem Env: | Sort-Object Name | ForEach-Object {
            if ($_.Name -notmatch 'TOKEN|SECRET|KEY|PASSWORD|COOKIE') {
              '{0}={1}' -f $_.Name, $_.Value
            }
          } | Set-Content -Encoding UTF8 (Join-Path $Diag 'env.txt')
          if (Test-Path '.github\workflows') {
            $wfDest = Join-Path $Diag '.github\workflows'
            New-Item -ItemType Directory -Path $wfDest -Force | Out-Null
            Copy-Item -Recurse -Force '.github\workflows\*' $wfDest
            $wfCopyDir = Join-Path $Diag 'wf'
            New-Item -ItemType Directory -Path $wfCopyDir -Force | Out-Null
            Get-ChildItem -Path '.github\workflows' -Filter *.yml -File -ErrorAction SilentlyContinue | ForEach-Object {
              Copy-Item -Force $_.FullName (Join-Path $wfCopyDir $_.Name)
              Copy-Item -Force $_.FullName (Join-Path $wfCopyDir ($_.Name + '.txt'))
            }
          }

      - name: Inventory collected files
        id: inventory
        shell: pwsh
        run: |
          $Diag = "${{ steps.prep.outputs.DIAG }}"
          $items = Get-ChildItem -Path $Diag -Recurse -File -Force -ErrorAction SilentlyContinue
          if (-not $items) { $items = @() }
          $manifestFiles = @()
          foreach ($item in $items) {
            $relative = $item.FullName.Substring($Diag.Length + 1).Replace('\\','/')
            $manifestFiles += [PSCustomObject]@{
              path         = $relative
              size         = $item.Length
              sha256       = (Get-FileHash -Algorithm SHA256 -LiteralPath $item.FullName).Hash
              modified_utc = $item.LastWriteTimeUtc.ToString('o')
            }
          }
          $manifest = [PSCustomObject]@{
            run_id        = '${{ github.run_id }}'
            run_attempt   = '${{ github.run_attempt }}'
            sha           = '${{ github.sha }}'
            generated_utc = (Get-Date).ToUniversalTime().ToString('o')
            files         = $manifestFiles
          }
          $manifest | ConvertTo-Json -Depth 4 | Set-Content -Encoding UTF8 (Join-Path $Diag 'inventory.json')
          $bulletLines = [System.Collections.Generic.List[string]]::new()
          $plainLines = [System.Collections.Generic.List[string]]::new()
          $htmlLines = [System.Collections.Generic.List[string]]::new()
          foreach ($seed in @('<!doctype html>', '<meta charset="utf-8">', '<title>Artifact inventory</title>', '<body><main><h1>Artifact inventory</h1><ul>')) {
            $null = $htmlLines.Add($seed)
          }

          foreach ($item in $items | Sort-Object FullName) {
            $relative = $item.FullName.Substring($Diag.Length + 1).Replace('\\','/')
            $size = '{0:N0}' -f $item.Length
            $safe = $relative -replace '&', '&amp;' -replace '<', '&lt;' -replace '>', '&gt;' -replace '"', '&quot;'
            $null = $bulletLines.Add(('- {0} bytes - `{1}`' -f $size, $relative))
            $null = $plainLines.Add(('{0} bytes{1}{2}' -f $size, [char]9, $relative))
            $null = $htmlLines.Add("<li><code>$safe</code> <span>($size bytes)</span></li>")
          }

          if ($bulletLines.Count -eq 0) {
            $null = $bulletLines.Add('- (no files captured)')
            $null = $plainLines.Add('no files captured')
            $null = $htmlLines.Add('<li>(no files captured)</li>')
          }

          $null = $htmlLines.Add('</ul></main></body>')

          $joined = $bulletLines.ToArray() -join "`n"
          $joined | Set-Content -Encoding UTF8 (Join-Path $Diag 'inventory.md')
          ($plainLines.ToArray() -join "`n") | Set-Content -Encoding UTF8 (Join-Path $Diag 'inventory.txt')
          ($htmlLines.ToArray() -join "`n") | Set-Content -Encoding UTF8 (Join-Path $Diag 'inventory.html')
          [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes($joined)) | ForEach-Object {
            "inventory_b64=$_" | Out-File -FilePath $env:GITHUB_OUTPUT -Encoding ascii -Append
          }

      - name: Publish diagnostics index
        shell: bash
        env:
          DIAG: ${{ steps.prep.outputs.DIAG }}
          ARTIFACTS: ${{ steps.prep.outputs.ARTIFACTS }}
          REPO: ${{ github.repository }}
          SHA: ${{ github.sha }}
          RUN_ID: ${{ github.run_id }}
          RUN_ATTEMPT: ${{ github.run_attempt }}
          RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
          SHORTSHA: ${{ steps.prep.outputs.SHORTSHA }}
          INVENTORY_B64: ${{ steps.inventory.outputs.inventory_b64 }}
          BATCH_RUN_ID: ${{ steps.fetch_batch.outputs.run_id }}
          BATCH_RUN_ATTEMPT: ${{ steps.fetch_batch.outputs.run_attempt }}
          SITE: ${{ steps.prep.outputs.SITE }}
        run: |
          python tools/diag/publish_index.py

      - name: Append job summary
        shell: pwsh
        run: |
          $Run = "${{ github.run_id }}"
          $Att = "${{ github.run_attempt }}"
          $ownerRepo = "${{ github.repository }}"
          $parts = $ownerRepo.Split('/')
          if ($parts.Count -eq 2) {
            $bundle = "https://$($parts[0]).github.io/$($parts[1])/diag/$Run-$Att/"
            "### Diagnostics bundle" | Out-File -Append $env:GITHUB_STEP_SUMMARY
            "- [$bundle]($bundle)" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          }

      - uses: actions/configure-pages@v4
        if: ${{ github.event_name != 'pull_request' }}

      - name: Upload Pages artifact
        if: ${{ github.event_name != 'pull_request' }}
        uses: actions/upload-pages-artifact@v3
        with:
          path: ${{ steps.prep.outputs.SITE }}

      - name: Deploy to GitHub Pages
        if: ${{ github.event_name != 'pull_request' }}
        id: deploy
        uses: actions/deploy-pages@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
