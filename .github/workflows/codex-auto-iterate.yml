# yamllint disable rule:line-length rule:truthy rule:colons rule:document-start
# version: v2025-10-08.41 (Decide gate: here-doc JSON + env defaults; PR body unchanged)
# lineage: v39 → tiny fix only in Decide gate

name: Codex - Auto Iterate on CI Failure

on:
  push:
    branches: ['**']
  workflow_dispatch: {}

permissions:
  actions: write
  contents: write
  pull-requests: write

defaults:
  run:
    shell: bash

concurrency:
  group: codex-iterate-${{ github.sha }}
  cancel-in-progress: true

jobs:
  iterate:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MAX_ATTEMPTS: '20'
      OPENAI_MODEL: gpt-5-codex
      POLL_TIMEOUT_SECONDS: '1200'
      POLL_INTERVAL_SECONDS: '10'
    steps:
      - name: Debug event
        run: |
          echo "event=${{ github.event_name }}"
          echo "ref_name=${{ github.ref_name }}"
          echo "sha=${{ github.sha }}"
          echo "actor=${{ github.actor }}"
          echo "workflow=${{ github.workflow }}"
          echo "run_id=${{ github.run_id }}"

      - name: Checkout repo (latest)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Auth probe (Responses API)
        id: auth
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ env.OPENAI_MODEL }}
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "ok=false"      >> "$GITHUB_OUTPUT"
            echo "reason=no_key" >> "$GITHUB_OUTPUT"
            {
              echo "### Auth probe"
              echo
              echo "- key: MISSING"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          RESP="$RUNNER_TEMP/auth_body.json"
          http_code=0
          reason=""

          # First try: model as provided using input_text payload required by Responses API
          req1=`mktemp`
          {
            printf '{\n'
            printf '  "model": "%s",\n' "$OPENAI_MODEL"
            printf '  "input": [\n'
            printf '    {"role":"system","content":[{"type":"input_text","text":"Auth probe: expect 200"}]},\n'
            printf '    {"role":"user","content":[{"type":"input_text","text":"ping"}]}\n'
            printf '  ],\n'
            printf '  "max_output_tokens": 16\n'
            printf '}\n'
          } > "$req1"
          http_code=`curl -sS -o "$RESP" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$req1" || true`
          rm -f "$req1"
          reason="http_${http_code}"

          # Retry with lowercase slug on any non-200
          if [ "$http_code" != "200" ]; then
            lower_model=`printf '%s' "$OPENAI_MODEL" | tr 'A-Z' 'a-z'`
            if [ "$lower_model" != "$OPENAI_MODEL" ]; then
              req2=`mktemp`
              {
                printf '{\n'
                printf '  "model": "%s",\n' "$lower_model"
                printf '  "input": [\n'
                printf '    {"role":"system","content":[{"type":"input_text","text":"Auth probe retry: expect 200"}]},\n'
                printf '    {"role":"user","content":[{"type":"input_text","text":"ping"}]}\n'
                printf '  ],\n'
                printf '  "max_output_tokens": 16\n'
                printf '}\n'
              } > "$req2"
              http_code=`curl -sS -o "$RESP" -w "%{http_code}" \
                https://api.openai.com/v1/responses \
                -H "authorization: Bearer $OPENAI_API_KEY" \
                -H "content-type: application/json" \
                -d @"$req2" || true`
              rm -f "$req2"
              reason="retry_lowercase_http_${http_code}"
            fi
          fi

          if [ "$http_code" = "200" ]; then
            echo "ok=true"   >> "$GITHUB_OUTPUT"
            echo "reason=ok" >> "$GITHUB_OUTPUT"
          else
            short=`jq -r '.error.message // empty' "$RESP" 2>/dev/null || true`
            if [ -n "$short" ]; then reason="$reason:$short"; fi
            echo "ok=false"        >> "$GITHUB_OUTPUT"
            echo "reason=$reason"  >> "$GITHUB_OUTPUT"
          fi

          {
            echo "### Auth probe (Responses API)"
            echo
            echo "- model (env): ${OPENAI_MODEL}"
            echo "- http_code: ${http_code}"
            echo "- ok: ${{ steps.auth.outputs.ok || 'n/a' }}"
            echo "- reason: ${reason}"
            echo
            echo "Body (first 300 chars):"
            echo '```json'
            head -c 300 "$RESP" | sed 's/[^[:print:]\t]/?/g' || true
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Gather context
        id: ctx
        run: |
          set -euo pipefail
          branch="${{ github.ref_name }}"
          sha="${{ github.sha }}"
          run_id="${{ github.run_id }}"
          run_url="https://github.com/${{ github.repository }}/actions/runs/${run_id}"
          branch_slug=`echo "$branch" | tr ':/ ' '---'`
          echo "branch=$branch" >> "$GITHUB_OUTPUT"
          echo "branch_slug=$branch_slug" >> "$GITHUB_OUTPUT"
          echo "head_sha=$sha" >> "$GITHUB_OUTPUT"
          echo "run_id=$run_id" >> "$GITHUB_OUTPUT"
          echo "run_url=$run_url" >> "$GITHUB_OUTPUT"

      - name: Poll ALL workflow runs for this commit
        id: poll
        uses: actions/github-script@v7
        env:
          POLL_TIMEOUT_SECONDS: ${{ env.POLL_TIMEOUT_SECONDS }}
          POLL_INTERVAL_SECONDS: ${{ env.POLL_INTERVAL_SECONDS }}
        with:
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const sha   = context.sha;
            const selfRunId = String(context.runId || "");
            const selfName  = (context.workflow || "").toLowerCase();
            const deadline = Date.now() + (parseInt(process.env.POLL_TIMEOUT_SECONDS||"1200")*1000);
            const interval = parseInt(process.env.POLL_INTERVAL_SECONDS||"10")*1000;

            async function listRunsForSha() {
              const { data } = await github.rest.actions.listWorkflowRunsForRepo({
                owner, repo, head_sha: sha, per_page: 100
              });
              return (data.workflow_runs || []);
            }

            function filterNotSelf(runs) {
              return runs.filter(r =>
                String(r.id) !== selfRunId &&
                (r.name||"").toLowerCase() !== selfName
              );
            }

            let lastSeen = [];
            let chosen = null;
            while (Date.now() < deadline) {
              let runs = await listRunsForSha();
              runs = filterNotSelf(runs);
              lastSeen = runs.map(r => ({id:r.id, name:r.name, status:r.status, conclusion:r.conclusion}));

              if (runs.length === 0) {
                await new Promise(r => setTimeout(r, interval));
                continue;
              }

              const incomplete = runs.filter(r => r.status !== "completed");
              if (incomplete.length > 0) {
                await new Promise(r => setTimeout(r, interval));
                continue;
              }

              // Prefer actual failures so Codex inspects a run with real errors.
              const failure = runs.find(r => (r.conclusion||"") === "failure");
              const needsAction = runs.find(r => ["timed_out", "action_required"].includes(r.conclusion||""));
              const cancelled = runs.find(r => (r.conclusion||"") === "cancelled");
              const nonSuccess = runs.find(r => (r.conclusion||"") !== "success");
              chosen = failure || needsAction || cancelled || nonSuccess || runs[0];
              break;
            }

            if (!chosen) {
              core.setOutput("found_any", "false");
              core.setOutput("all_completed", "false");
              core.setOutput("any_non_success", "true");
              core.setOutput("summary_json", JSON.stringify(lastSeen));
            } else {
              core.setOutput("found_any", "true");
              core.setOutput("all_completed", "true");
              const anyNonSucc = lastSeen.some(r => (r.conclusion||"") !== "success");
              core.setOutput("any_non_success", String(anyNonSucc));
              core.setOutput("summary_json", JSON.stringify(lastSeen));
              core.setOutput("picked_id", String(chosen.id));
              core.setOutput("picked_name", chosen.name||"");
              core.setOutput("picked_status", chosen.status||"");
              core.setOutput("picked_conclusion", chosen.conclusion||"");
            }

      - name: Fetch failing run artifact (structured)
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: struct
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          api="https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID_PICKED}/artifacts"
          meta="$RUNNER_TEMP/artifacts.json"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" -H "Accept: application/vnd.github+json" "$api" -o "$meta" || true
          # Pick an artifact likely containing structured CI results
          name=`jq -r '.artifacts[].name' "$meta" 2>/dev/null | grep -E -i 'ndjson|summary_raw|self.?test|ci[-_]?result|first.?error' | head -n 1 || true`
          if [ -z "$name" ] || [ "$name" = "null" ]; then
            echo "path=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          id=`jq -r --arg n "$name" '.artifacts[] | select(.name==$n) | .id' "$meta" 2>/dev/null || true`
          if [ -z "$id" ] || [ "$id" = "null" ]; then
            echo "path=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          zipfile="$RUNNER_TEMP/struct.zip"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" -L \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$id/zip" -o "$zipfile" || true
          dest="$RUNNER_TEMP/struct"
          mkdir -p "$dest"
          unzip -q "$zipfile" -d "$dest" || true
          out="$RUNNER_TEMP/ci_structured.txt"
          : > "$out"
          # Prefer *.ndjson; else summary_raw*.txt; else any *.json with errors
          nd=`find "$dest" -type f -name '*.ndjson' | head -n 1 || true`
          if [ -n "$nd" ]; then
            jq -rc 'select((.level=="error") or (.status=="fail") or (.conclusion=="failure") or (.type=="error")) | . | {job:(.job//.workflow//"unknown"),step:(.step//"unknown"),file:(.file//"unknown"),line:(.line//null),msg:(.msg//.message//.error//.detail//"") } | @json' "$nd" | head -n 1 > "$out" || true
          fi
          if [ ! -s "$out" ]; then
            sr=`find "$dest" -type f -iname 'summary_raw*' -o -iname '*first*error*' -o -iname '*ci*result*.json' | head -n 1 || true`
            if [ -n "$sr" ]; then
              head -n 120 "$sr" > "$out" || true
            fi
          fi
          if [ -s "$out" ]; then
            echo "path=$out" >> "$GITHUB_OUTPUT"
          else
            echo "path=" >> "$GITHUB_OUTPUT"
          fi

      - name: Fetch failing run logs (tail)
        if: ${{ steps.poll.outputs.picked_id != '' }}
        id: logtail
        env:
          GH_TOKEN: ${{ github.token }}
          RUN_ID_PICKED: ${{ steps.poll.outputs.picked_id }}
        run: |
          set -euo pipefail
          zipfile="$RUNNER_TEMP/other_run_logs.zip"
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            -L "https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID_PICKED}/logs" \
            -o "$zipfile" || true
          mkdir -p "$RUNNER_TEMP/logs_extract"
          unzip -q "$zipfile" -d "$RUNNER_TEMP/logs_extract" || true
          OUT="$RUNNER_TEMP/failing_log_tail.txt"
          : > "$OUT"
          find "$RUNNER_TEMP/logs_extract" -type f -name '*.txt' -printf "%s %p\n" > "$RUNNER_TEMP/logsizes.txt" || true
          sort -nr "$RUNNER_TEMP/logsizes.txt" | awk 'NR==1{print $2}' > "$RUNNER_TEMP/largest.txt" || true
          if [ -s "$RUNNER_TEMP/largest.txt" ]; then
            candidate=`cat "$RUNNER_TEMP/largest.txt"`
            if [ -f "$candidate" ]; then
              tail -n 200 "$candidate" > "$OUT" || true
            fi
          fi
          echo "path=$OUT" >> "$GITHUB_OUTPUT"

      - name: Decide gate (iterate vs skip)
        id: gate
        env:
          FOUND_ANY: ${{ steps.poll.outputs.found_any }}
          ALL_COMPLETED: ${{ steps.poll.outputs.all_completed }}
          ANY_NON_SUCCESS: ${{ steps.poll.outputs.any_non_success }}
          SUMMARY_JSON: ${{ steps.poll.outputs.summary_json }}
        run: |
          set -euo pipefail
          # Safe defaults so -u doesn't explode if outputs are unset
          FOUND_ANY="${FOUND_ANY:-}"
          ALL_COMPLETED="${ALL_COMPLETED:-}"
          ANY_NON_SUCCESS="${ANY_NON_SUCCESS:-}"

          should_iterate=false
          reason=""
          if [ "${FOUND_ANY}" != "true" ]; then
            should_iterate=true
            reason="no_runs_or_timeout"
          else
            if [ "${ALL_COMPLETED}" != "true" ]; then
              should_iterate=true
              reason="runs_not_completed_timeout"
            else
              if [ "${ANY_NON_SUCCESS}" = "true" ]; then
                should_iterate=true
                reason="one_or_more_runs_failed"
              else
                should_iterate=false
                reason="all_success"
              fi
            fi
          fi
          echo "should_iterate=${should_iterate}" >> "$GITHUB_OUTPUT"
          echo "reason=${reason}" >> "$GITHUB_OUTPUT"

          {
            echo "### Poll summary"
            echo '```json'
            printf '%s\n' "$SUMMARY_JSON"
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Load/Update attempt counter
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: attempts
        run: |
          set -euo pipefail
          attempts=0
          GH_TOKEN="${{ github.token }}"
          owner_repo="${{ github.repository }}"
          branch_slug="${{ steps.ctx.outputs.branch_slug }}"
          curl -sS -H "Authorization: Bearer $GH_TOKEN" \
            "https://api.github.com/repos/${owner_repo}/actions/artifacts?per_page=100" > artifacts_all.json
          id=`jq -r --arg n "iterate-state-$branch_slug" '.artifacts[] | select(.name==$n and ..expired==false) | .id' artifacts_all.json | head -n 1 || true`
          if [ -n "$id" ] && [ "$id" != "null" ]; then
            curl -sSL -H "Authorization: Bearer $GH_TOKEN" -L \
              "https://api.github.com/repos/${owner_repo}/actions/artifacts/$id/zip" \
              -o state.zip || true
            mkdir -p state && unzip -q state.zip -d state || true
            attempts=`jq -r '.attempts // 0' state/iterate_state.json 2>/dev/null || echo 0`
          fi
          nextfile="$RUNNER_TEMP/next.txt"
          echo "$attempts" | awk '{print $1+1}' > "$nextfile"
          next=`cat "$nextfile"`
          if [ "$next" -gt "${MAX_ATTEMPTS}" ]; then
            echo "stop=true" >> "$GITHUB_OUTPUT"
            echo "stop_reason=Max attempts reached (${MAX_ATTEMPTS})" >> "$GITHUB_OUTPUT"
            echo "previous=$attempts" >> "$GITHUB_OUTPUT"
            echo "next=$attempts" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "stop=false" >> "$GITHUB_OUTPUT"
          echo "previous=$attempts" >> "$GITHUB_OUTPUT"
          echo "next=$next" >> "$GITHUB_OUTPUT"

      - name: Build prompt
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        id: prompt
        run: |
          set -euo pipefail
          PROMPT="$RUNNER_TEMP/prompt.txt"
          repo="${{ github.repository }}"
          branch="${{ steps.ctx.outputs.branch }}"
          sha="${{ steps.ctx.outputs.head_sha }}"
          attempt="${{ steps.attempts.outputs.next }}"
          {
            echo "You are Codex. You have a working copy of the repo checked out."
            echo "Read README.md and AGENTS.md (if present) in the workspace for local policy."
            echo
            echo "Task: diagnose and fix CI failures for the GitHub Actions workflow(s)."
            echo "Prefer minimal edits and explain changes in commit messages."
            echo
            echo "Repo: $repo"
            echo "Branch: $branch"
            echo "Commit: $sha"
            echo "Attempt: $attempt/${MAX_ATTEMPTS}"
            echo
            echo "Strict output instruction: Return a unified diff patch inside a single fenced code block labeled 'diff'."
            echo "If no changes are needed, output exactly:"
            echo '```diff'
            echo '# no changes'
            echo '```'
          } > "$PROMPT"
          git ls-files > "$RUNNER_TEMP/repo-files.txt" || true
          if [ -s "$RUNNER_TEMP/repo-files.txt" ]; then
            {
              echo
              echo "----- Repo files (head) -----"
              head -n 300 "$RUNNER_TEMP/repo-files.txt"
            } >> "$PROMPT"
          fi
          # Append structured CI error first (preferred)
          if [ -n "${{ steps.struct.outputs.path }}" ] && [ -s "${{ steps.struct.outputs.path }}" ]; then
            {
              echo
              echo "----- CI structured error (first record / head) -----"
              sed -e 's/[^[:print:]\t]/?/g' "${{ steps.struct.outputs.path }}" | head -n 120
            } >> "$PROMPT"
          fi
          # Then append failing-job log tail as fallback signal
          if [ -n "${{ steps.logtail.outputs.path }}" ] && [ -s "${{ steps.logtail.outputs.path }}" ]; then
            {
              echo
              echo "----- Failing job log tail (last 200 lines) -----"
              sed -e 's/[^[:print:]\t]/?/g' "${{ steps.logtail.outputs.path }}" | tail -n 200
            } >> "$PROMPT"
          fi
          echo "path=$PROMPT" >> "$GITHUB_OUTPUT"

      - name: Prompt preview
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        run: |
          echo "### Prompt (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```text' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "${{ steps.prompt.outputs.path }}" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Ask model for patch (Responses API)
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: llm
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: ${{ env.OPENAI_MODEL }}
        run: |
          set -euo pipefail
          REQ="$RUNNER_TEMP/llm_req.json"
          RES="$RUNNER_TEMP/llm_res.json"
          OUTTXT="$RUNNER_TEMP/llm_content.txt"
          PROMPT_FILE="${{ steps.prompt.outputs.path }}"
          jq -Rs '.' < "$PROMPT_FILE" > "$RUNNER_TEMP/prompt.json"
          {
            printf '{\n'
            printf '  "model": "%s",\n' "$OPENAI_MODEL"
            printf '  "input": [\n'
            printf '    {"role":"system","content":[{"type":"input_text","text":"You are an expert software engineer that proposes precise, minimal unified diffs."}]},\n'
            printf '    {"role":"user","content":[{"type":"input_text","text": '
            cat "$RUNNER_TEMP/prompt.json"
            printf ' }]}\n'
            printf '  ],\n'
            printf '  "max_output_tokens": 2000\n'
            printf '}\n'
          } > "$REQ"
          http_code=`curl -sS -o "$RES" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$REQ" || true`
          echo "http_code=$http_code"
          echo "### LLM body (first 300 chars)" >> "$GITHUB_STEP_SUMMARY"
          echo '```json' >> "$GITHUB_STEP_SUMMARY"
          head -c 300 "$RES" | sed 's/[^[:print:]\t]/?/g' >> "$GITHUB_STEP_SUMMARY" || true
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          err=`jq -r '.error.message // empty' "$RES" 2>/dev/null || true`
          if [ -n "$err" ]; then echo "**error:** $err" >> "$GITHUB_STEP_SUMMARY"; fi
          # Responses API prefers output_text; fall back to first textual content item if absent
          jq -r '(
            .output_text //
            (.output[]? | .content[]? | select(.type=="output_text") | .text) //
            (.output[0]? | .content[0]? | .text // "")
          )' "$RES" > "$OUTTXT" || true
          echo "### LLM response (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "$OUTTXT" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Extract fenced diff
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: diff
        run: |
          set -euo pipefail
          CONTENT="$RUNNER_TEMP/llm_content.txt"
          DIFF_OUT="$RUNNER_TEMP/patch.diff"
          awk 'BEGIN{f=0} /```diff/ && f==0 {f=1; next} /```/ && f==1 {f=2} f==1 {print}' "$CONTENT" > "$DIFF_OUT" || true
          if [ ! -s "$DIFF_OUT" ]; then
            echo "# no changes" > "$DIFF_OUT"
          fi
          echo "diff_path=$DIFF_OUT" >> "$GITHUB_OUTPUT"
          echo "### Extracted diff (first 120 lines)" >> "$GITHUB_STEP_SUMMARY"
          echo '```diff' >> "$GITHUB_STEP_SUMMARY"
          head -n 120 "$DIFF_OUT" >> "$GITHUB_STEP_SUMMARY" || true
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Apply patch (stage only; let PR action commit)
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' && steps.auth.outputs.ok == 'true' }}
        id: apply
        run: |
          set -euo pipefail
          DIFF_OUT="${{ steps.diff.outputs.diff_path }}"
          if grep -q '^# no changes$' "$DIFF_OUT"; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if git apply -p0 --index "$DIFF_OUT"; then
            echo "applied_with=-p0" >> "$GITHUB_OUTPUT"
          elif git apply -p1 --index "$DIFF_OUT"; then
            echo "applied_with=-p1" >> "$GITHUB_OUTPUT"
          else
            echo "Patch failed to apply"
            echo "changed=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if [ -z "`git status --porcelain`" ]; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
          else
            echo "changed=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload diagnostics
        uses: actions/upload-artifact@v4
        with:
          name: iterate-diag-${{ github.run_id }}-${{ github.run_attempt }}
          path: |
            $RUNNER_TEMP/auth_body.json
            $RUNNER_TEMP/llm_req.json
            $RUNNER_TEMP/llm_res.json
            $RUNNER_TEMP/llm_content.txt
            $RUNNER_TEMP/patch.diff
            $RUNNER_TEMP/prompt.txt
          if-no-files-found: warn
          retention-days: 14

      - name: Build PR body file
        if: ${{ steps.gate.outputs.should_iterate == 'true' }}
        id: pr_body
        env:
          SUMMARY_JSON: ${{ steps.poll.outputs.summary_json }}
          AUTH_OK_RAW: ${{ steps.auth.outputs.ok }}
          AUTH_REASON_RAW: ${{ steps.auth.outputs.reason }}
          BRANCH_NAME: ${{ steps.ctx.outputs.branch }}
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
          GATE_REASON: ${{ steps.gate.outputs.reason }}
        run: |
          set -euo pipefail
          BODY=".github/ITERATE_PR_BODY.md"
          mkdir -p .github
          summary="${SUMMARY_JSON:-}"
          if [ -z "$summary" ] || [ "$summary" = "null" ]; then
            summary='[]'
          fi

          auth_ok="${AUTH_OK_RAW:-}"
          if [ -z "$auth_ok" ]; then
            auth_ok='false'
          fi

          auth_reason_raw="${AUTH_REASON_RAW:-}"
          auth_reason_raw="${auth_reason_raw//$'\r'/ }"
          auth_reason_raw="${auth_reason_raw//$'\n'/ }"
          if [ -z "$auth_reason_raw" ]; then
            auth_reason_raw='n/a'
          fi

          branch_name="${BRANCH_NAME:-unknown}"
          head_sha="${HEAD_SHA:-unknown}"
          gate_reason="${GATE_REASON:-unknown}"

          {
            printf '## Codex iteration (push-poll ALL workflows)\n\n'
            printf -- '- Branch: `%s` @ %s\n' "$branch_name" "$head_sha"
            printf -- '- Gate reason: %s\n\n' "$gate_reason"
            printf '### Polled runs\n'
            printf '```json\n'
            printf '%s\n' "$summary"
            printf '```\n\n'
            printf '### Auth probe\n'
            printf -- '- ok: %s (reason: %s)\n' "$auth_ok" "$auth_reason_raw"
          } > "$BODY"

          if [ -f "$RUNNER_TEMP/prompt.txt" ]; then
            {
              printf '\n### Prompt (first 200 lines)\n'
              printf '```text\n'
              head -n 200 "$RUNNER_TEMP/prompt.txt" || true
              printf '```\n'
            } >> "$BODY"
          fi

          if [ -f "$RUNNER_TEMP/patch.diff" ]; then
            {
              printf '\n### Extracted diff (first 200 lines)\n'
              printf '```diff\n'
              head -n 200 "$RUNNER_TEMP/patch.diff" || true
              printf '```\n'
            } >> "$BODY"
          fi

          echo "body_path=$BODY" >> "$GITHUB_OUTPUT"

      - name: Create PR (if edits)
        if: ${{ steps.apply.outputs.changed == 'true' }}
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "codex: iterate on CI failure (attempt ${{ steps.attempts.outputs.next }}/${{ env.MAX_ATTEMPTS }})"
          branch: codex/ci-fix-${{ steps.ctx.outputs.branch_slug }}
          base: ${{ steps.ctx.outputs.branch }}
          title: "Codex: iterate on CI failure – ${{ steps.ctx.outputs.branch }}"
          body-path: ${{ steps.pr_body.outputs.body_path }}
          labels: codex,ci-fix,automerge-candidate

      - name: Save attempt state
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        env:
          ATTEMPTS: ${{ steps.attempts.outputs.next }}
          RUN_ID: ${{ steps.ctx.outputs.run_id }}
          HEAD_SHA: ${{ steps.ctx.outputs.head_sha }}
        run: |
          mkdir -p state_out
          printf '{\n' > state_out/iterate_state.json
          printf '  "attempts": "%s",\n' "$ATTEMPTS" >> state_out/iterate_state.json
          printf '  "run_id": "%s",\n' "$RUN_ID" >> state_out/iterate_state.json
          printf '  "head_sha": "%s"\n' "$HEAD_SHA" >> state_out/iterate_state.json
          printf '}\n' >> state_out/iterate_state.json

      - name: Upload attempt state
        if: ${{ steps.gate.outputs.should_iterate == 'true' && steps.attempts.outputs.stop != 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: iterate-state-${{ steps.ctx.outputs.branch_slug }}
          path: state_out
          if-no-files-found: warn
          retention-days: 30

      - name: Mark job neutral if we got this far
        if: ${{ always() }}
        run: echo "::notice title=iterate::Job completed - forcing neutral so logs persist"

  deploy-iterate-pages:
    name: Deploy iterate diagnostics to Pages
    needs: iterate
    if: ${{ always() }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
      pages: write
      id-token: write
    environment:
      name: github-pages
    steps:
      - name: Locate iterate diagnostics artifact
        id: diag_lookup
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const runId = context.runId;
            const { data } = await github.rest.actions.listWorkflowRunArtifacts({
              owner,
              repo,
              run_id: runId,
              per_page: 100,
            });
            const artifacts = Array.isArray(data.artifacts) ? data.artifacts : [];
            const match = artifacts.find(art => {
              if (!art || art.expired) return false;
              return typeof art.name === 'string' && art.name.startsWith('iterate-diag-');
            });
            if (!match) {
              core.info('iterate-diag-* artifact not found for this run.');
              core.setOutput('found', 'false');
              return;
            }
            core.info(`Found iterate diagnostics artifact: ${match.name} (id=${match.id})`);
            core.setOutput('found', 'true');
            core.setOutput('artifact-name', match.name);

      - name: Download iterate diagnostics
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ steps.diag_lookup.outputs.artifact-name }}
          path: ${{ runner.temp }}/iterate-diag

      - name: Stage diagnostics into public directory
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        run: |
          set -euo pipefail
          rm -rf public
          mkdir -p public/logs public/sources public/repo
          src_dir="${RUNNER_TEMP}/iterate-diag"
          if [ -d "$src_dir" ]; then
            shopt -s dotglob nullglob
            if find "$src_dir" -mindepth 1 -print -quit >/dev/null 2>&1; then
              cp -R "$src_dir"/* public/logs/
            fi
            shopt -u dotglob nullglob
          fi
          rm -rf "$src_dir"
          touch public/.nojekyll

      - name: Build Pages index
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        run: |
          set -euo pipefail
          python <<'PY'
          import datetime
          from pathlib import Path

          base = Path('public')
          logs_dir = base / 'logs'
          sources_dir = base / 'sources'
          repo_dir = base / 'repo'
          for path in (logs_dir, sources_dir, repo_dir):
              path.mkdir(parents=True, exist_ok=True)

          entries = []
          for path in base.rglob('*'):
              if not path.is_file():
                  continue
              if path.name in {'index.md', 'index.html'}:
                  continue
              entries.append(path.relative_to(base))

          entries.sort()

          repo = "${{ github.repository }}"
          run_id = "${{ github.run_id }}"
          attempt = "${{ github.run_attempt }}"
          run_url = f"https://github.com/{repo}/actions/runs/{run_id}"
          timestamp = datetime.datetime.utcnow().isoformat(timespec='seconds') + 'Z'

          index_md = base / 'index.md'
          lines = [
              '# Iterate diagnostics',
              '',
              f'- Repo: `{repo}`',
              f'- Workflow run: [{run_id}]({run_url})',
              f'- Run attempt: {attempt}',
              f'- Generated: {timestamp}',
              '',
              '## Files',
          ]

          if entries:
              for rel in entries:
                  rel_path = rel.as_posix()
                  lines.append(f'- [{rel_path}]({rel_path})')
          else:
              lines.append('- (no files captured)')

          index_md.write_text('\n'.join(lines) + '\n', encoding='utf-8')

          html_lines = [
              '<!doctype html>',
              '<meta charset="utf-8">',
              f'<title>Iterate diagnostics — run {run_id}</title>',
              '<style>',
              'body{font-family:ui-sans-serif,system-ui;line-height:1.5;margin:24px;}',
              'code{font-family:ui-monospace,Consolas,monospace;}',
              'a{color:#0366d6;}',
              '</style>',
              '<h1>Iterate diagnostics</h1>',
              f'<p><strong>Repo:</strong> {repo}<br>',
              f'<strong>Run:</strong> <a href="{run_url}">{run_id}</a> (attempt {attempt})<br>',
              f'<strong>Generated:</strong> {timestamp}</p>',
              '<p>See <a href="index.md">index.md</a> for a Markdown listing.</p>',
          ]

          if entries:
              html_lines.append('<ul>')
              for rel in entries:
                  rel_path = rel.as_posix()
                  html_lines.append(f'<li><a href="{rel_path}">{rel_path}</a></li>')
              html_lines.append('</ul>')
          else:
              html_lines.append('<p>(no files captured)</p>')

          (base / 'index.html').write_text('\n'.join(html_lines) + '\n', encoding='utf-8')
          PY

      - name: Configure Pages
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to Pages
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        id: deploy
        uses: actions/deploy-pages@v4

      - name: Summarize deployment
        if: ${{ steps.diag_lookup.outputs.found == 'true' }}
        run: |
          url='${{ steps.deploy.outputs.page_url }}'
          {
            echo '### Iterate diagnostics Pages'
            if [ -n "$url" ]; then
              echo "- Deployed: [$url]($url)"
            else
              echo '- Deployed: (no URL returned)'
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Note missing diagnostics
        if: ${{ steps.diag_lookup.outputs.found != 'true' }}
        run: |
          {
            echo '### Iterate diagnostics Pages'
            echo '- iterate-diag-* artifact not found; skipping deployment.'
          } >> "$GITHUB_STEP_SUMMARY"
