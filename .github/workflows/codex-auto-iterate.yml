# yamllint disable rule:line-length rule:truthy rule:colons rule:document-start
name: Codex - Auto Iterate on CI Failure

on:
  workflow_run:
    workflows:
      - Batch syntax/run check
    types:
      - completed

permissions:
  contents: write
  actions: read
  pages: write
  id-token: write
  pull-requests: write

env:
  ITERATION_CAP: '4'
  MINI_PROBE_MODEL: gpt-4o-mini
  CODEX_MODEL: codex-gpt-5

jobs:
  upstream-success:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
      - name: Upstream run succeeded — no iteration required
        run: |
          set -euo pipefail
          run_id="${{ github.event.workflow_run.id }}"
          run_url="${{ github.event.workflow_run.html_url }}"
          attempt="${{ github.event.workflow_run.run_attempt }}"
          {
            echo '### Codex auto-iterate';
            echo;
            echo "- Upstream run: [${run_id}](${run_url})";
            echo "- Upstream attempt: ${attempt}";
            echo '- Conclusion: success (iteration skipped).';
          } >> "$GITHUB_STEP_SUMMARY"

  iterate:
    if: ${{ github.event.workflow_run.conclusion != 'success' }}
    runs-on: ubuntu-latest
    environment:
      name: codex-auto-iterate
    steps:
      - name: Initialize summary
        id: init
        run: |
          set -euo pipefail
          run_id="${{ github.event.workflow_run.id }}"
          run_url="${{ github.event.workflow_run.html_url }}"
          attempt="${{ github.event.workflow_run.run_attempt }}"
          branch="${{ github.event.workflow_run.head_branch }}"
          sha="${{ github.event.workflow_run.head_sha }}"
          {
            echo '### Codex auto-iterate';
            echo;
            echo "- Upstream run: [${run_id}](${run_url}) (attempt ${attempt})";
            echo "- Upstream conclusion: ${{ github.event.workflow_run.conclusion }}";
            echo "- Head branch: ${branch:-'(unknown)'}";
            echo "- Head SHA: ${sha}";
          } >> "$GITHUB_STEP_SUMMARY"
          iter_dir="$RUNNER_TEMP/codex/${run_id}-${attempt}"
          mkdir -p "$iter_dir/public"
          echo "ITER_DIR=$iter_dir" >> "$GITHUB_ENV"
          echo "ITER_PUBLIC=$iter_dir/public" >> "$GITHUB_ENV"
          echo "UPSTREAM_RUN_ID=${run_id}" >> "$GITHUB_ENV"
          echo "UPSTREAM_RUN_ATTEMPT=${attempt}" >> "$GITHUB_ENV"
          echo "UPSTREAM_RUN_URL=${run_url}" >> "$GITHUB_ENV"
          echo "HEAD_SHA=${sha}" >> "$GITHUB_ENV"
          echo "HEAD_BRANCH=${branch}" >> "$GITHUB_ENV"

      - name: Collect upstream context
        id: upstream
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const fs = require('fs');
            const path = process.env.ITER_DIR + '/codex_upstream.json';
            const run = context.payload.workflow_run;
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const artifacts = await github.paginate(
              github.rest.actions.listWorkflowRunArtifacts,
              { owner, repo, run_id: run.id, per_page: 100 }
            );
            const jobs = await github.paginate(
              github.rest.actions.listJobsForWorkflowRun,
              { owner, repo, run_id: run.id, per_page: 100 }
            );
            const info = {
              repository: `${owner}/${repo}`,
              run_id: run.id,
              run_attempt: run.run_attempt,
              conclusion: run.conclusion,
              status: run.status,
              event: run.event,
              head_branch: run.head_branch,
              head_sha: run.head_sha,
              html_url: run.html_url,
              logs_url: run.logs_url,
              artifacts_url: run.artifacts_url,
              check_suite_url: run.check_suite_url,
              created_at: run.created_at,
              updated_at: run.updated_at,
              artifacts: artifacts.map(a => ({
                id: a.id,
                name: a.name,
                size_in_bytes: a.size_in_bytes,
                expired: a.expired,
                archive_download_url: a.archive_download_url,
                created_at: a.created_at,
                expires_at: a.expires_at,
              })),
              jobs: jobs.map(j => ({
                id: j.id,
                name: j.name,
                html_url: j.html_url,
                conclusion: j.conclusion,
                started_at: j.started_at,
                completed_at: j.completed_at,
              })),
            };
            fs.writeFileSync(path, JSON.stringify(info, null, 2));
            core.setOutput('json_path', path);

      - name: Build Codex nudge payloads
        id: nudge
        env:
          ITER_DIR: ${{ env.ITER_DIR }}
          GITHUB_TOKEN: ${{ github.token }}
          REPO: ${{ github.repository }}
        run: |
          set -euo pipefail
          python <<'PY'
          import io
          import json
          import os
          import urllib.request
          import zipfile
          from pathlib import Path

          iter_dir = Path(os.environ['ITER_DIR'])
          upstream = json.load(open(iter_dir / 'codex_upstream.json', 'r', encoding='utf-8'))
          repo = upstream.get('repository', os.environ.get('REPO', ''))
          head_sha = upstream.get('head_sha', '')
          run_url = upstream.get('html_url', '')
          artifacts = upstream.get('artifacts', [])

          iter_dir.mkdir(parents=True, exist_ok=True)

          diag_url = ''
          token = os.environ.get('GITHUB_TOKEN', '')
          for artifact in artifacts:
            name = artifact.get('name') or ''
            url = artifact.get('archive_download_url') or ''
            if not name.startswith('codex_nudge_url-'):
              continue
            if not url:
              continue
            req = urllib.request.Request(
              url,
              headers={'Authorization': f'Bearer {token}', 'Accept': 'application/vnd.github+json'}
            )
            try:
              with urllib.request.urlopen(req, timeout=60) as resp:
                blob = resp.read()
              with zipfile.ZipFile(io.BytesIO(blob)) as zf:
                for member in zf.namelist():
                  if member.endswith('codex_nudge_url.txt'):
                    data = zf.read(member).decode('utf-8', errors='replace')
                    (iter_dir / 'codex_nudge_url.txt').write_text(data, encoding='utf-8')
                    diag_url = data.strip().splitlines()[0] if data.strip() else ''
                    break
            except Exception as exc:
              note = f"Diagnostics artifact download failed: {exc}\n"
              (iter_dir / 'codex_nudge_url.txt').write_text(note, encoding='utf-8')
            if diag_url:
              break

          if not (iter_dir / 'codex_nudge_url.txt').exists():
            (iter_dir / 'codex_nudge_url.txt').write_text('Diagnostics URL: (not available)\n', encoding='utf-8')

          repo_zip = ''
          if repo and head_sha:
            repo_zip = f"https://api.github.com/repos/{repo}/zipball/{head_sha}"

          lines = [
            f"Upstream run: {run_url}",
            f"Head branch: {upstream.get('head_branch')}",
            f"Head SHA: {head_sha}",
            f"Repository: {repo}",
          ]
          if diag_url:
            lines.append(f"Diagnostics: {diag_url}")
          if repo_zip:
            lines.append(f"Repository zip: {repo_zip}")
          lines.append('Artifacts:')
          for artifact in artifacts:
            url = artifact.get('archive_download_url') or ''
            lines.append(f"  - {artifact.get('name')}: {url}")

          (iter_dir / 'codex_nudge.txt').write_text('\n'.join(lines) + '\n', encoding='utf-8')

          if not (iter_dir / 'codex_exec.log').exists():
            (iter_dir / 'codex_exec.log').write_text('Codex iteration log initialized.\n', encoding='utf-8')

          status = {
            'diag_url': diag_url,
            'repo_zip': repo_zip,
          }
          (iter_dir / 'status.json').write_text(json.dumps(status, indent=2), encoding='utf-8')
          PY

      - name: Check OPENAI_API_KEY
        id: key
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ITER_DIR: ${{ env.ITER_DIR }}
        run: |
          set -euo pipefail
          key_state='present'
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            key_state='missing'
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "- OPENAI_API_KEY: missing" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "- OPENAI_API_KEY: detected" >> "$GITHUB_STEP_SUMMARY"
          fi
          KEY_STATE="$key_state" python <<'PY'
          import json
          import os
          from pathlib import Path

          path = Path(os.environ['ITER_DIR']) / 'status.json'
          data = {}
          if path.exists():
            try:
              data = json.loads(path.read_text(encoding='utf-8'))
            except Exception:
              data = {}
          data['openai_key'] = os.environ.get('KEY_STATE', 'unknown')
          path.write_text(json.dumps(data, indent=2), encoding='utf-8')
          PY

      - name: Mini preflight (gpt-4o-mini)
        if: ${{ steps.key.outputs.present == 'true' }}
        id: preflight
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MINI_PROBE_MODEL: ${{ env.MINI_PROBE_MODEL }}
          ITER_DIR: ${{ env.ITER_DIR }}
        run: |
          set -euo pipefail
          req="$RUNNER_TEMP/preflight_req.json"
          resp="$ITER_DIR/preflight_response.json"
          {
            printf '{\n';
            printf '  "model": "%s",\n' "$MINI_PROBE_MODEL";
            printf '  "input": [\n';
            printf '    {"role":"system","content":[{"type":"input_text","text":"Codex iterate preflight"}]},\n';
            printf '    {"role":"user","content":[{"type":"input_text","text":"ping"}]}\n';
            printf '  ],\n';
            printf '  "max_output_tokens": 1\n';
            printf '}\n';
          } > "$req"
          http_code=$(curl -sS -o "$resp" -w "%{http_code}" \
            https://api.openai.com/v1/responses \
            -H "authorization: Bearer $OPENAI_API_KEY" \
            -H "content-type: application/json" \
            -d @"$req" || echo '000')
          echo "http_code=$http_code"
          if [ "$http_code" = "200" ]; then
            echo "ok=true" >> "$GITHUB_OUTPUT"
            echo "- Mini preflight: ok (http 200)" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "ok=false" >> "$GITHUB_OUTPUT"
            echo "- Mini preflight: failed (http ${http_code})" >> "$GITHUB_STEP_SUMMARY"
          fi
          HTTP_CODE="$http_code" python <<'PY'
          import json
          import os
          from pathlib import Path

          path = Path(os.environ['ITER_DIR']) / 'status.json'
          data = {}
          if path.exists():
            try:
              data = json.loads(path.read_text(encoding='utf-8'))
            except Exception:
              data = {}
          data['preflight_http'] = os.environ.get('HTTP_CODE', '000')
          data['preflight_ok'] = os.environ.get('HTTP_CODE', '') == '200'
          path.write_text(json.dumps(data, indent=2), encoding='utf-8')
          PY

      - name: Checkout head commit
        if: ${{ steps.preflight.outputs.ok == 'true' }}
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ github.event.workflow_run.head_sha }}
          fetch-depth: 0

      - name: Configure git author
        if: ${{ steps.preflight.outputs.ok == 'true' }}
        run: |
          set -euo pipefail
          git config user.name "Codex CI"
          git config user.email "codex-ci@users.noreply.github.com"

      - name: Run Codex iteration attempts
        if: ${{ steps.preflight.outputs.ok == 'true' }}
        id: iterate_attempts
        env:
          ITER_DIR: ${{ env.ITER_DIR }}
          ITERATION_CAP: ${{ env.ITERATION_CAP }}
          CODEX_MODEL: ${{ env.CODEX_MODEL }}
        run: |
          set -euo pipefail
          log="$ITER_DIR/codex_exec.log"
          touch "$log"
          cli_present=0
          if command -v codex >/dev/null 2>&1; then
            echo "[INFO] codex CLI detected" | tee -a "$log"
            attempt=1
            while [ "$attempt" -le "$ITERATION_CAP" ]; do
              echo "\n=== Codex attempt ${attempt}/${ITERATION_CAP} ===" | tee -a "$log"
              codex exec --model "$CODEX_MODEL" --sandbox workspace-write exec >> "$log" 2>&1 || true
              if git diff --quiet && git diff --staged --quiet; then
                echo "[INFO] Attempt ${attempt}: no changes produced" | tee -a "$log"
              else
                echo "[INFO] Attempt ${attempt}: changes detected" | tee -a "$log"
                break
              fi
              attempt=$(( attempt + 1 ))
            done
            cli_present=1
          else
            echo "[WARN] codex CLI not found on runner PATH; skipping automated attempts." | tee -a "$log"
          fi
          echo "cli_present=${cli_present}" >> "$GITHUB_OUTPUT"
          if [ "$cli_present" -eq 0 ]; then
            echo "- Codex CLI: not found (iteration skipped)" >> "$GITHUB_STEP_SUMMARY"
          fi
          CLI_STATE="$cli_present" python <<'PY'
          import json
          import os
          from pathlib import Path

          path = Path(os.environ['ITER_DIR']) / 'status.json'
          data = {}
          if path.exists():
            try:
              data = json.loads(path.read_text(encoding='utf-8'))
            except Exception:
              data = {}
          data['codex_cli_present'] = os.environ.get('CLI_STATE', '0') == '1'
          path.write_text(json.dumps(data, indent=2), encoding='utf-8')
          PY

      - name: Upload Codex context artifact
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: codex-context-${{ github.run_id }}-${{ github.run_attempt }}-${{ github.event.workflow_run.id }}
          path: |
            ${{ env.ITER_DIR }}/codex_upstream.json
            ${{ env.ITER_DIR }}/codex_nudge.txt
            ${{ env.ITER_DIR }}/codex_nudge_url.txt
            ${{ env.ITER_DIR }}/codex_exec.log
            ${{ env.ITER_DIR }}/preflight_response.json
            ${{ env.ITER_DIR }}/status.json
          if-no-files-found: ignore
          retention-days: 14

      - name: Build diagnostics site
        if: ${{ always() }}
        id: build_public
        env:
          ITER_DIR: ${{ env.ITER_DIR }}
          ITER_PUBLIC: ${{ env.ITER_PUBLIC }}
          RUN_URL: ${{ env.UPSTREAM_RUN_URL }}
          RUN_ID: ${{ env.UPSTREAM_RUN_ID }}
          RUN_ATTEMPT: ${{ env.UPSTREAM_RUN_ATTEMPT }}
          HEAD_SHA: ${{ env.HEAD_SHA }}
          HEAD_BRANCH: ${{ env.HEAD_BRANCH }}
        run: |
          set -euo pipefail
          pub_dir=$(python <<'PY'
          import datetime
          import json
          import os
          from pathlib import Path

          iter_dir = Path(os.environ['ITER_DIR'])
          public = Path(os.environ['ITER_PUBLIC'])
          public.mkdir(parents=True, exist_ok=True)
          log_path = iter_dir / 'codex_exec.log'
          status_path = iter_dir / 'status.json'
          diag_link = ''
          status = {}
          if status_path.exists():
            try:
              status = json.loads(status_path.read_text(encoding='utf-8'))
              diag_link = status.get('diag_url', '')
            except Exception:
              status = {}
          log_tail = ''
          if log_path.exists():
            lines = log_path.read_text(encoding='utf-8', errors='replace').splitlines()
            log_tail = '\n'.join(lines[-20:])
          preflight_http = status.get('preflight_http', 'n/a')
          key_state = status.get('openai_key', 'unknown')
          cli_present = status.get('codex_cli_present', False)
          run_url = os.environ.get('RUN_URL', '')
          run_id = os.environ.get('RUN_ID', '')
          run_attempt = os.environ.get('RUN_ATTEMPT', '')
          head_sha = os.environ.get('HEAD_SHA', '')
          head_branch = os.environ.get('HEAD_BRANCH', '')

          md_lines = [
            '# Codex iterate diagnostics',
            '',
            f'- Upstream run: [{run_id}]({run_url}) (attempt {run_attempt})',
            f'- Head branch: `{head_branch}`',
            f'- Head SHA: `{head_sha}`',
            f'- OPENAI_API_KEY: {key_state}',
            f'- codex CLI present: {"yes" if cli_present else "no"}',
            f'- Mini preflight HTTP: {preflight_http}',
            f'- Diagnostics URL from batch: {diag_link or "(missing)"}',
            '',
            '## Codex execution log (tail)',
            '```text',
            log_tail or '(log file missing)',
            '```',
          ]
          (public / 'index.md').write_text('\n'.join(md_lines) + '\n', encoding='utf-8')

          html = f"""
          <!doctype html>
          <meta charset="utf-8">
          <title>Codex iterate diagnostics — run {run_id}</title>
          <style>
            body{{font-family:ui-sans-serif,system-ui;line-height:1.5;margin:24px}}
            code,pre{{font-family:ui-monospace,Consolas,monospace}}
            a{{color:#0366d6}}
          </style>
          <h1>Codex iterate diagnostics</h1>
          <p><strong>Upstream run:</strong> <a href="{run_url}">{run_id}</a> (attempt {run_attempt})<br>
             <strong>Head branch:</strong> {head_branch}<br>
             <strong>Head SHA:</strong> {head_sha}<br>
             <strong>OPENAI_API_KEY:</strong> {key_state}<br>
             <strong>codex CLI present:</strong> {"yes" if cli_present else "no"}<br>
             <strong>Mini preflight HTTP:</strong> {preflight_http}<br>
             <strong>Batch diagnostics:</strong> {diag_link or '(missing)'}
          </p>
          <h2>Codex execution log (tail)</h2>
          <pre>{log_tail or '(log file missing)'}</pre>
          """
          (public / 'index.html').write_text(html + '\n', encoding='utf-8')

          print(public.as_posix())
          PY
          )
          echo "public_dir=$pub_dir" >> "$GITHUB_OUTPUT"

      - name: Configure Pages
        if: ${{ always() }}
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        if: ${{ always() }}
        uses: actions/upload-pages-artifact@v3
        with:
          name: codex-pages-${{ github.run_id }}-${{ github.run_attempt }}-${{ github.event.workflow_run.id }}
          path: ${{ env.ITER_PUBLIC }}

      - name: Deploy to Pages
        if: ${{ always() }}
        id: deploy
        uses: actions/deploy-pages@v4

      - name: Record deployment URL
        if: ${{ always() }}
        run: |
          set -euo pipefail
          url='${{ steps.deploy.outputs.page_url }}'
          if [ -n "$url" ]; then
            echo "- Codex diagnostics: [$url]($url)" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "- Codex diagnostics: (deploy did not return a URL)" >> "$GITHUB_STEP_SUMMARY"
